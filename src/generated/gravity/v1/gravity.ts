// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.0
//   protoc               v6.33.0
// source: gravity/v1/gravity.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import {
  type CallOptions,
  ChannelCredentials,
  Client,
  type ClientOptions,
  type ClientUnaryCall,
  type handleUnaryCall,
  makeGenericClientConstructor,
  Metadata,
  type ServiceError,
  type UntypedServiceImplementation,
} from "@grpc/grpc-js";
import { Empty } from "../../google/protobuf/empty";
import { Timestamp } from "../../google/protobuf/timestamp";

export const protobufPackage = "gravity.v1";

/** GetHotkeysResponse is the response message for getting hotkeys */
export interface GetHotkeysResponse {
  /** hotkeys: the hotkeys */
  hotkeys: string[];
}

/** BuyMarketplaceDatasetRequest is the request to purchase a dataset */
export interface BuyMarketplaceDatasetRequest {
  /** gravity_task_id: the marketplace dataset's gravity task id to purchase */
  gravityTaskId: string;
}

/** BuyMarketplaceDatasetResponse is the response to a dataset purchase */
export interface BuyMarketplaceDatasetResponse {
  /** success: whether the purchase succeeded */
  success: boolean;
  /** message: optional detail */
  message: string;
  /** purchase_transaction_id: billing transaction id */
  purchaseTransactionId: string;
}

/** UserMarketplaceDataset represents a single owned dataset record */
export interface UserMarketplaceDataset {
  gravityTaskId: string;
  createdAt?: Date | undefined;
  purchasePriceCents: number;
  purchaseTransactionId: string;
}

/** GetUserMarketplaceDatasetsResponse lists owned datasets */
export interface GetUserMarketplaceDatasetsResponse {
  userDatasets: UserMarketplaceDataset[];
}

/** UpsertHotkeysRequest is the request message for upserting hotkeys */
export interface UpsertHotkeysRequest {
  /** hotkeys: the hotkeys to upsert */
  hotkeys: string[];
}

/** UpsertMarketplaceTaskSuggestionsRequest is the request message for upserting marketplace task suggestions */
export interface UpsertMarketplaceTaskSuggestionsRequest {
  /** gravity_task_id: the id of the gravity task */
  gravityTaskId: string;
  /** suggested_gravity_task_ids: the ids of the suggested gravity tasks */
  suggestedGravityTaskIds: string[];
}

/** GetMarketplaceTaskSuggestionsRequest is the request message for getting marketplace task suggestions */
export interface GetMarketplaceTaskSuggestionsRequest {
  /** gravity_task_id: the id of the gravity task */
  gravityTaskId: string;
}

/** GetMarketplaceTaskSuggestionsResponse is the response message for getting marketplace task suggestions */
export interface GetMarketplaceTaskSuggestionsResponse {
  /** suggested_gravity_task_ids: the ids of the suggested gravity tasks */
  suggestedGravityTaskIds: string[];
}

/** PopularTag is a single popular tag along with its count */
export interface PopularTag {
  /** tag: the popular tag */
  tag: string;
  /** count: the count of the tag */
  count: number;
}

/** GetPopularTagsResponse is the response message for getting popular tags */
export interface GetPopularTagsResponse {
  /** popular_tags: the popular tags */
  popularTags: PopularTag[];
}

/** PublishDatasetRequest is the request message for publishing a dataset */
export interface PublishDatasetRequest {
  /** dataset_id: the ID of the dataset */
  datasetId: string;
}

/** PersistentDatasetWorkflow */
export interface PersistentDatasetWorkflow {
  /** dataset_id: the ID of the dataset workflow */
  datasetId: string;
  /** status: the status of the dataset workflow */
  status: string;
}

/** AddPersistentDatasetWorkflowsRequest */
export interface AddPersistentDatasetWorkflowsRequest {
  datasetWorkflows: PersistentDatasetWorkflow[];
}

/** UpsertMarketplaceTaskMetadataRequest */
export interface UpsertMarketplaceTaskMetadataRequest {
  /** gravity_task_id: the id of the gravity task */
  gravityTaskId: string;
  /** description: a description of the curated gravity task */
  description: string;
  /** name: the name of the curated task */
  name: string;
  /** image_url: points to an image related to the task */
  imageUrl: string;
  /** tags: a set of tags for this task */
  tags: string[];
}

/** GetMarketplaceDatasetsRequest is the request message for getting marketplace datasets */
export interface GetMarketplaceDatasetsRequest {
  /** popular: whether to return popular datasets */
  popular: boolean;
}

/** GetPersistentDatasetWorkflowsResponse returns recent dataset workflows */
export interface GetPersistentDatasetWorkflowsResponse {
  datasetWorkflows: PersistentDatasetWorkflow[];
}

/**
 * Crawler is a single crawler workflow that registers a single job
 * (platform/topic) on SN13's dynamic desirability engine
 */
export interface Crawler {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
  /** criteria: the contents of the job and the notification details */
  criteria?: CrawlerCriteria | undefined;
  /** start_time: the time the crawler was created */
  startTime?: Date | undefined;
  /** deregistration_time: the time the crawler was deregistered */
  deregistrationTime?: Date | undefined;
  /** archive_time: the time the crawler was archived */
  archiveTime?: Date | undefined;
  /** state: the current state of the crawler */
  state?: CrawlerState | undefined;
  /**
   * dataset_workflows: the IDs of the dataset workflows that are associated
   * with the crawler
   */
  datasetWorkflows: string[];
  /** parquet_paths: the paths to the raw miner files collected */
  parquetPaths: string[];
}

/** PersistentGravityTask: a single persistent gravity task */
export interface PersistentGravityTask {
  /** gravity_task_id: the id of the gravity task */
  gravityTaskId: string;
  /** ingest_dt: the date the task was ingested */
  ingestDt: string;
}

/**
 * GetPersistentGravityTasksResponse: message containing persistent task ids and
 * their ingest dt
 */
export interface GetPersistentGravityTasksResponse {
  /** persistent_gravity_tasks: the persistent gravity tasks */
  persistentGravityTasks: PersistentGravityTask[];
}

/** UpsertCrawlerRequest for upserting a crawler and its criteria */
export interface UpsertCrawlerRequest {
  /** gravity_task_id: the parent workflow id -- in this case the multicrawler id */
  gravityTaskId: string;
  /** crawler: the crawler to upsert into the database */
  crawler?: Crawler | undefined;
}

/** UpsertResponse is the response message for upserting a crawler */
export interface UpsertResponse {
  /**
   * message: the message of upserting a crawler (currently hardcoded to
   * "success")
   */
  message: string;
}

/** UpsertGravityTaskRequest for upserting a gravity task */
export interface UpsertGravityTaskRequest {
  /** gravity_task: the gravity task to upsert into the database */
  gravityTask?: GravityTaskRequest | undefined;
}

/**
 * UpsertGravityTaskResponse is the response message for upserting a gravity
 * task
 */
export interface UpsertGravityTaskResponse {
  /**
   * message: the message of upserting a gravity task (currently hardcoded to
   * "success")
   */
  message: string;
}

/** GravityTaskRequest represents the data needed to upsert a gravity task */
export interface GravityTaskRequest {
  /** id: the ID of the gravity task */
  id: string;
  /** name: the name of the gravity task */
  name: string;
  /** status: the status of the gravity task */
  status: string;
  /** start_time: the start time of the gravity task */
  startTime?: Date | undefined;
  /** notification_to: the notification email address */
  notificationTo: string;
  /** notification_link: the notification redirect link */
  notificationLink: string;
}

/** UpsertCrawlerCriteriaRequest for upserting a crawler and its criteria */
export interface InsertCrawlerCriteriaRequest {
  /** crawler_id: the id of the crawler */
  crawlerId: string;
  /** crawler_criteria: the crawler criteria to upsert into the database */
  crawlerCriteria?: CrawlerCriteria | undefined;
}

/** CrawlerCriteria is the contents of the job and the notification details */
export interface CrawlerCriteria {
  /** platform: the platform of the job ('x' or 'reddit') */
  platform: string;
  /** topic: the topic of the job (e.g. '#ai' for X, 'r/ai' for Reddit) */
  topic?: string | undefined;
  /** notification: the details of the notification to be sent to the user */
  notification?: CrawlerNotification | undefined;
  /** mock: Used for testing purposes (optional, defaults to false) */
  mock: boolean;
  /** user_id: the ID of the user who created the gravity task */
  userId: string;
  /** keyword: the keyword to search for in the job (optional) */
  keyword?: string | undefined;
  /** post_start_datetime: the start date of the job (optional) */
  postStartDatetime?: Date | undefined;
  /** post_end_datetime: the end date of the job (optional) */
  postEndDatetime?: Date | undefined;
}

/** PersistentTopic is the contents of the persistent topic */
export interface PersistentTopic {
  /** platform: the platform of the job ('x' or 'reddit') */
  platform: string;
  /** topic: the topic of the job (e.g. '#ai' for X, 'r/ai' for Reddit) */
  topic?: string | undefined;
}

export interface PersistentTopicResponse {
  /** persistent_topics: the persistent topics */
  persistentTopics: PersistentTopic[];
}

/** CrawlerNotification is the details of the notification to be sent to the user */
export interface CrawlerNotification {
  /** to: the email address of the user */
  to: string;
  /** link: the redirect link in the email where the user can view the dataset */
  link: string;
}

/** HfRepo is a single Hugging Face repository that contains data for a crawler */
export interface HfRepo {
  /** repo_name: the name of the Hugging Face repository */
  repoName: string;
  /** row_count: the number of rows in the repository for the crawler criteria */
  rowCount: number;
  /** last_update: the last recorded time the repository was updated */
  lastUpdate: string;
}

/** CrawlerState is the current state of the crawler */
export interface CrawlerState {
  /**
   * status: the current status of the crawler
   *   "Pending"   -- Crawler is pending submission to the SN13 Validator
   *   "Submitted" -- Crawler is submitted to the SN13 Validator
   *   "Running"   -- Crawler is running (we got the first update)
   *   "Completed" -- Crawler is completed (timer expired)
   *   "Cancelled" -- Crawler is cancelled by user via cancellation of workflow
   *   "Archived"  -- Crawler is archived (now read-only i.e. no new dataset)
   *   "Failed"    -- Crawler failed to run
   */
  status: string;
  /** bytes_collected: the estimated number of bytes collected by the crawler */
  bytesCollected: number;
  /** records_collected: the estimated number of records collected by the crawler */
  recordsCollected: number;
  /** repos: the Hugging Face repositories that contain data for a crawler */
  repos: HfRepo[];
}

/** GravityTaskState is the current state of a gravity task */
export interface GravityTaskState {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
  /** name: the name given by the user of the gravity task */
  name: string;
  /** status: the current status of the gravity task */
  status: string;
  /** start_time: the time the gravity task was created */
  startTime?: Date | undefined;
  /**
   * crawler_ids: the IDs of the crawler workflows that are associated with the
   * gravity task
   */
  crawlerIds: string[];
  /**
   * crawler_workflows: the crawler workflows that are associated with the
   * gravity task
   */
  crawlerWorkflows: Crawler[];
}

/** GravityMarketplaceTaskState is the current state of a gravity task for marketplace display */
export interface GravityMarketplaceTaskState {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
  /** name: the name given by the user of the gravity task */
  name: string;
  /** status: the current status of the gravity task */
  status: string;
  /** start_time: the time the gravity task was created */
  startTime?: Date | undefined;
  /**
   * crawler_ids: the IDs of the crawler workflows that are associated with the
   * gravity task
   */
  crawlerIds: string[];
  /**
   * crawler_workflows: the crawler workflows that are associated with the
   * gravity task
   */
  crawlerWorkflows: Crawler[];
  /** task_records_collected: the total number of records collected across all crawlers for this task */
  taskRecordsCollected: number;
  /** task_bytes_collected: the total number of bytes collected across all crawlers for this task */
  taskBytesCollected: number;
  /** description: description from gravity_marketplace_task_metadata */
  description: string;
  /** image_url: image url from gravity_marketplace_task_metadata */
  imageUrl: string;
  /** view_count: number of views from gravity_marketplace_task_download_history */
  viewCount: number;
  /** download_count: number of downloads from gravity_marketplace_task_download_history */
  downloadCount: number;
  /** tags: set of tags from gravity_marketplace_task_tags (accumulated) */
  tags: string[];
}

/**
 * GetGravityTasksRequest is the request message for listing gravity tasks for a
 * user
 */
export interface GetGravityTasksRequest {
  /**
   * gravity_task_id: the ID of the gravity task (optional, if not provided, all
   * gravity tasks for the user will be returned)
   */
  gravityTaskId?: string | undefined;
  /** include_crawlers: whether to include the crawler states in the response */
  includeCrawlers?: boolean | undefined;
}

/**
 * GetGravityTasksResponse is the response message for listing gravity tasks for
 * a user
 */
export interface GetGravityTasksResponse {
  /** gravity_task_states: the current states of the gravity tasks */
  gravityTaskStates: GravityTaskState[];
}

/** GravityTask defines a crawler's criteria for a single job (platform/topic) */
export interface GravityTask {
  /** topic: the topic of the job (e.g. '#ai' for X, 'r/ai' for Reddit) */
  topic?: string | undefined;
  /** platform: the platform of the job ('x' or 'reddit') */
  platform: string;
  /** keyword: the keyword to search for in the job (optional) */
  keyword?: string | undefined;
  /** post_start_datetime: the start date of the job (optional) */
  postStartDatetime?: Date | undefined;
  /** post_end_datetime: the end date of the job (optional) */
  postEndDatetime?: Date | undefined;
}

/**
 * NotificationRequest is the request message for sending a notification to a
 * user when a dataset is ready to download
 */
export interface NotificationRequest {
  /**
   * type: the type of notification to send ('email' is only supported
   * currently)
   */
  type: string;
  /**
   * address: the address to send the notification to (only email addresses are
   * supported currently)
   */
  address: string;
  /**
   * redirect_url: the URL to include in the notication message that redirects
   * the user to any built datasets
   */
  redirectUrl?: string | undefined;
}

/** GetCrawlerRequest is the request message for getting a crawler */
export interface GetCrawlerRequest {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
}

/** GetMarketplaceCrawlersResponse is the response message holding all marketplace crawlers */
export interface GetMarketplaceCrawlersResponse {
  /** crawler_id: the ID of the crawler */
  crawlerId: string[];
}

/** CompleteCrawlerRequest is the request message for cancelling a crawler */
export interface CompleteCrawlerRequest {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
  /** status: ending status of the crawler */
  status: string;
}

/** GetCrawlerResponse is the response message for getting a crawler */
export interface GetCrawlerResponse {
  /** crawler: the crawler */
  crawler?: Crawler | undefined;
}

/**
 * CreateGravityTaskRequest is the request message for creating a new gravity
 * task
 */
export interface CreateGravityTaskRequest {
  /** gravity_tasks: the criteria for the crawlers that will be created */
  gravityTasks: GravityTask[];
  /**
   * name: the name of the gravity task (optional, default will generate a
   * random name)
   */
  name: string;
  /**
   * notification_requests: the details of the notification to be sent to the
   * user when a dataset
   *   that is automatically generated upon completion of the crawler is ready
   *   to download (optional)
   */
  notificationRequests: NotificationRequest[];
  /**
   * gravity_task_id: the ID of the gravity task (optional, default will
   * generate a random ID)
   */
  gravityTaskId?: string | undefined;
}

/**
 * CreateGravityTaskResponse is the response message for creating a new gravity
 * task
 */
export interface CreateGravityTaskResponse {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
}

/**
 * BuildDatasetRequest is the request message for manually requesting the
 * building of a dataset for a single crawler
 */
export interface BuildDatasetRequest {
  /** crawler_id: the ID of the crawler that will be used to build the dataset */
  crawlerId: string;
  /**
   * notification_requests: the details of the notification to be sent to the
   * user when the dataset is ready to download (optional)
   */
  notificationRequests: NotificationRequest[];
  /**
   * max_rows: the maximum number of rows to include in the dataset (optional,
   * defaults to 500)
   */
  maxRows: number;
  /** is_marketplace: determines whether the dataset to build is for marketplace */
  isMarketplace?: boolean | undefined;
}

/**
 * BuildDatasetResponse is the response message for manually requesting the
 * building of a dataset for a single crawler
 * - dataset: the dataset that was built
 */
export interface BuildDatasetResponse {
  /** dataset_id: the ID of the dataset */
  datasetId: string;
  /** dataset: the dataset that was built */
  dataset?: Dataset | undefined;
}

/**
 * BuildAllDatasetsRequest is the request message for building all datasets
 * belonging to a workflow
 */
export interface BuildAllDatasetsRequest {
  /** gravityTaskId specifies which task to build */
  gravityTaskId: string;
  /** specifies how much of each crawler to build for workflow */
  buildCrawlersConfig: BuildDatasetRequest[];
  /** is_marketplace: determines whether the datasets to build are for marketplace */
  isMarketplace?: boolean | undefined;
}

export interface BuildAllDatasetsResponse {
  gravityTaskId: string;
  datasets: Dataset[];
}

export interface AddPersistentGravityTaskRequest {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
}

export interface Nebula {
  /** error: nebula build error message */
  error: string;
  /** file_size_bytes: the size of the file in bytes */
  fileSizeBytes: number;
  /** url: the URL of the file */
  url: string;
}

/** Dataset contains the progress and results of a dataset build */
export interface Dataset {
  /** crawler_workflow_id: the ID of the parent crawler for this dataset */
  crawlerWorkflowId: string;
  /** create_date: the date the dataset was created */
  createDate?: Date | undefined;
  /** expire_date: the date the dataset will expire (be deleted) */
  expireDate?: Date | undefined;
  /** files: the details about the dataset files that are included in the dataset */
  files: DatasetFile[];
  /** status: the status of the dataset */
  status: string;
  /** status_message: the message of the status of the dataset */
  statusMessage: string;
  /** steps: the progress of the dataset build */
  steps: DatasetStep[];
  /** total_steps: the total number of steps in the dataset build */
  totalSteps: number;
  /** nebula: the details about the nebula that was built */
  nebula?: Nebula | undefined;
}

/**
 * UpsertDatasetRequest contains the dataset id to insert and the dataset
 * details
 */
export interface UpsertDatasetRequest {
  /** dataset_id: a unique id for the dataset */
  datasetId: string;
  /** dataset: the details of the dataset */
  dataset?: Dataset | undefined;
}

/** UpsertNebulaRequest contains the dataset id and nebula details to upsert */
export interface UpsertNebulaRequest {
  /** dataset_id: a unique id for the dataset */
  datasetId: string;
  /** nebula_id: a unique id for the nebula */
  nebulaId: string;
  /** nebula: the details of the nebula */
  nebula?: Nebula | undefined;
}

/**
 * InsertDatasetFileRequest contains the dataset id to insert into and the
 * dataset file details
 */
export interface InsertDatasetFileRequest {
  /** dataset_id: the ID of the dataset to attach the file to */
  datasetId: string;
  /** files: the dataset files to insert */
  files: DatasetFile[];
}

/** DatasetFile contains the details about a dataset file */
export interface DatasetFile {
  /** file_name: the name of the file */
  fileName: string;
  /** file_size_bytes: the size of the file in bytes */
  fileSizeBytes: number;
  /** last_modified: the date the file was last modified */
  lastModified?: Date | undefined;
  /** num_rows: the number of rows in the file */
  numRows: number;
  /** s3_key: the key of the file in S3 (internal use only) */
  s3Key: string;
  /** url: the URL of the file (public use) */
  url: string;
}

/**
 * DatasetStep contains one step of the progress of a dataset build
 * (NOTE: each step varies in time and complexity)
 */
export interface DatasetStep {
  /** progress: the progress of this step in the dataset build (0.0 - 1.0) */
  progress: number;
  /** step: the step number of the dataset build (1-indexed) */
  step: number;
  /** step_name: description of what is happening in the step */
  stepName: string;
}

/** GetDatasetRequest is the request message for getting the status of a dataset */
export interface GetDatasetRequest {
  /** dataset_id: the ID of the dataset */
  datasetId: string;
}

/**
 * GetDatasetResponse is the response message for getting the status of a
 * dataset
 */
export interface GetDatasetResponse {
  /** dataset: the dataset that is being built */
  dataset?: Dataset | undefined;
}

/** CancelGravityTaskRequest is the request message for cancelling a gravity task */
export interface CancelGravityTaskRequest {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
}

/**
 * CancelGravityTaskResponse is the response message for cancelling a gravity
 * task
 */
export interface CancelGravityTaskResponse {
  /**
   * message: the message of the cancellation of the gravity task (currently
   * hardcoded to "success")
   */
  message: string;
}

/** CancelDatasetRequest is the request message for cancelling a dataset build */
export interface CancelDatasetRequest {
  /** dataset_id: the ID of the dataset */
  datasetId: string;
}

/** CancelDatasetResponse is the response message for cancelling a dataset build */
export interface CancelDatasetResponse {
  /**
   * message: the message of the cancellation of the dataset build (currently
   * hardcoded to "success")
   */
  message: string;
}

/** DatasetBillingCorrectionRequest is the request message for refunding a user */
export interface DatasetBillingCorrectionRequest {
  /** requested_row_count: number of rows expected by the user */
  requestedRowCount: number;
  /** actual_row_count: number of rows returned by gravity */
  actualRowCount: number;
}

/** DatasetBillingCorrectionResponse is the response message for refunding a user */
export interface DatasetBillingCorrectionResponse {
  /** refund_amount */
  refundAmount: number;
}

/**
 * GetMarketplaceDatasetsResponse returns the dataset metadata to be used in
 * Marketplace
 */
export interface GetMarketplaceDatasetsResponse {
  /** datasets: list of marketplace datasets */
  datasets: GravityMarketplaceTaskState[];
}

/**
 * GetGravityTaskDatasetFilesRequest is the request message for getting dataset
 * files for a gravity task
 */
export interface GetGravityTaskDatasetFilesRequest {
  /** gravity_task_id: the ID of the gravity task (required) */
  gravityTaskId: string;
}

/** CrawlerDatasetFiles contains dataset files for a specific crawler */
export interface CrawlerDatasetFiles {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
  /** dataset_files: the dataset files associated with this crawler */
  datasetFiles: DatasetFileWithId[];
}

/** CrawlerRawMinerFiles contains raw miner files for a specific crawler */
export interface CrawlerRawMinerFilesResponse {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
  /** s3_paths: the S3 paths associated with this crawler */
  s3Paths: string[];
}

/** DatasetFileWithId extends DatasetFile to include the dataset ID */
export interface DatasetFileWithId {
  /** dataset_id: the ID of the dataset this file belongs to */
  datasetId: string;
  /** file_name: the name of the file */
  fileName: string;
  /** file_size_bytes: the size of the file in bytes */
  fileSizeBytes: number;
  /** last_modified: the date the file was last modified */
  lastModified?: Date | undefined;
  /** num_rows: the number of rows in the file */
  numRows: number;
  /** s3_key: the key of the file in S3 (internal use only) */
  s3Key: string;
  /** url: the URL of the file (public use) */
  url: string;
  /** nebula_url: the url of a nebula */
  nebulaUrl: string;
}

/**
 * GetGravityTaskDatasetFilesResponse is the response message for getting
 * dataset files for a gravity task
 */
export interface GetGravityTaskDatasetFilesResponse {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
  /** crawler_dataset_files: dataset files grouped by crawler */
  crawlerDatasetFiles: CrawlerDatasetFiles[];
}

/**
 * GetCrawlerHistoryRequest is the request message for getting crawler history
 * associated to the provided gravity_task_id
 */
export interface GetCrawlerHistoryRequest {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
}

/** CrawlerHistoryEntry represents a single history entry for a crawler */
export interface CrawlerHistoryEntry {
  /** ingest_dt: the timestamp when this entry was ingested */
  ingestDt?: Date | undefined;
  /** records_collected: the number of records collected */
  recordsCollected: number;
  /** bytes_collected: the number of bytes collected */
  bytesCollected: number;
}

/**
 * CrawlerCriteriaAndHistory represents crawler information with criteria and
 * history
 */
export interface CrawlerCriteriaAndHistory {
  /** crawler_id: the ID of the crawler */
  crawlerId: string;
  /** platform: the platform from gravity_crawler_criteria */
  platform: string;
  /** topic: the topic from gravity_crawler_criteria */
  topic?: string | undefined;
  /** keyword: the keyword from gravity_crawler_criteria */
  keyword?: string | undefined;
  /** post_start_date: the start date for posts from gravity_crawler_criteria */
  postStartDate?: Date | undefined;
  /** post_end_date: the end date for posts from gravity_crawler_criteria */
  postEndDate?: Date | undefined;
  /** crawler_history: the history entries for this crawler */
  crawlerHistory: CrawlerHistoryEntry[];
}

/** GetCrawlerHistoryResponse is the response message for getting crawler history */
export interface GetCrawlerHistoryResponse {
  /** gravity_task_id: the ID of the gravity task */
  gravityTaskId: string;
  /** crawlers: the crawlers with their criteria and history */
  crawlers: CrawlerCriteriaAndHistory[];
}

/** GetCrawlerDataForDDSubmissionRequest is the request message for getting crawler data */
export interface GetCrawlerDataForDDSubmissionRequest {
  /** dsns: list of database connection strings to query */
  dsns: string[];
}

/** GetCrawlerDataForDDSubmissionResponse is the response message for crawler data */
export interface GetCrawlerDataForDDSubmissionResponse {
  /** crawlers: list of crawler data for DD submission */
  crawlers: CrawlerDataForDD[];
}

/** CrawlerDataForDD contains crawler information for DD submission */
export interface CrawlerDataForDD {
  crawlerId: string;
  platform: string;
  topic?: string | undefined;
  keyword?: string | undefined;
  postStartDatetime?: string | undefined;
  postEndDatetime?: string | undefined;
}

function createBaseGetHotkeysResponse(): GetHotkeysResponse {
  return { hotkeys: [] };
}

export const GetHotkeysResponse: MessageFns<GetHotkeysResponse> = {
  encode(
    message: GetHotkeysResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.hotkeys) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetHotkeysResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetHotkeysResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.hotkeys.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetHotkeysResponse {
    return {
      hotkeys: globalThis.Array.isArray(object?.hotkeys)
        ? object.hotkeys.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: GetHotkeysResponse): unknown {
    const obj: any = {};
    if (message.hotkeys?.length) {
      obj.hotkeys = message.hotkeys;
    }
    return obj;
  },

  create(base?: DeepPartial<GetHotkeysResponse>): GetHotkeysResponse {
    return GetHotkeysResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetHotkeysResponse>): GetHotkeysResponse {
    const message = createBaseGetHotkeysResponse();
    message.hotkeys = object.hotkeys?.map(e => e) || [];
    return message;
  },
};

function createBaseBuyMarketplaceDatasetRequest(): BuyMarketplaceDatasetRequest {
  return { gravityTaskId: "" };
}

export const BuyMarketplaceDatasetRequest: MessageFns<BuyMarketplaceDatasetRequest> =
  {
    encode(
      message: BuyMarketplaceDatasetRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): BuyMarketplaceDatasetRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseBuyMarketplaceDatasetRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): BuyMarketplaceDatasetRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
      };
    },

    toJSON(message: BuyMarketplaceDatasetRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<BuyMarketplaceDatasetRequest>,
    ): BuyMarketplaceDatasetRequest {
      return BuyMarketplaceDatasetRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<BuyMarketplaceDatasetRequest>,
    ): BuyMarketplaceDatasetRequest {
      const message = createBaseBuyMarketplaceDatasetRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      return message;
    },
  };

function createBaseBuyMarketplaceDatasetResponse(): BuyMarketplaceDatasetResponse {
  return { success: false, message: "", purchaseTransactionId: "" };
}

export const BuyMarketplaceDatasetResponse: MessageFns<BuyMarketplaceDatasetResponse> =
  {
    encode(
      message: BuyMarketplaceDatasetResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.success !== false) {
        writer.uint32(8).bool(message.success);
      }
      if (message.message !== "") {
        writer.uint32(18).string(message.message);
      }
      if (message.purchaseTransactionId !== "") {
        writer.uint32(26).string(message.purchaseTransactionId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): BuyMarketplaceDatasetResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseBuyMarketplaceDatasetResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 8) {
              break;
            }

            message.success = reader.bool();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.message = reader.string();
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.purchaseTransactionId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): BuyMarketplaceDatasetResponse {
      return {
        success: isSet(object.success)
          ? globalThis.Boolean(object.success)
          : false,
        message: isSet(object.message) ? globalThis.String(object.message) : "",
        purchaseTransactionId: isSet(object.purchaseTransactionId)
          ? globalThis.String(object.purchaseTransactionId)
          : "",
      };
    },

    toJSON(message: BuyMarketplaceDatasetResponse): unknown {
      const obj: any = {};
      if (message.success !== false) {
        obj.success = message.success;
      }
      if (message.message !== "") {
        obj.message = message.message;
      }
      if (message.purchaseTransactionId !== "") {
        obj.purchaseTransactionId = message.purchaseTransactionId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<BuyMarketplaceDatasetResponse>,
    ): BuyMarketplaceDatasetResponse {
      return BuyMarketplaceDatasetResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<BuyMarketplaceDatasetResponse>,
    ): BuyMarketplaceDatasetResponse {
      const message = createBaseBuyMarketplaceDatasetResponse();
      message.success = object.success ?? false;
      message.message = object.message ?? "";
      message.purchaseTransactionId = object.purchaseTransactionId ?? "";
      return message;
    },
  };

function createBaseUserMarketplaceDataset(): UserMarketplaceDataset {
  return {
    gravityTaskId: "",
    createdAt: undefined,
    purchasePriceCents: 0,
    purchaseTransactionId: "",
  };
}

export const UserMarketplaceDataset: MessageFns<UserMarketplaceDataset> = {
  encode(
    message: UserMarketplaceDataset,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    if (message.createdAt !== undefined) {
      Timestamp.encode(
        toTimestamp(message.createdAt),
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.purchasePriceCents !== 0) {
      writer.uint32(24).int64(message.purchasePriceCents);
    }
    if (message.purchaseTransactionId !== "") {
      writer.uint32(34).string(message.purchaseTransactionId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UserMarketplaceDataset {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUserMarketplaceDataset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createdAt = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.purchasePriceCents = longToNumber(reader.int64());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.purchaseTransactionId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UserMarketplaceDataset {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      createdAt: isSet(object.createdAt)
        ? fromJsonTimestamp(object.createdAt)
        : undefined,
      purchasePriceCents: isSet(object.purchasePriceCents)
        ? globalThis.Number(object.purchasePriceCents)
        : 0,
      purchaseTransactionId: isSet(object.purchaseTransactionId)
        ? globalThis.String(object.purchaseTransactionId)
        : "",
    };
  },

  toJSON(message: UserMarketplaceDataset): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.createdAt !== undefined) {
      obj.createdAt = message.createdAt.toISOString();
    }
    if (message.purchasePriceCents !== 0) {
      obj.purchasePriceCents = Math.round(message.purchasePriceCents);
    }
    if (message.purchaseTransactionId !== "") {
      obj.purchaseTransactionId = message.purchaseTransactionId;
    }
    return obj;
  },

  create(base?: DeepPartial<UserMarketplaceDataset>): UserMarketplaceDataset {
    return UserMarketplaceDataset.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<UserMarketplaceDataset>,
  ): UserMarketplaceDataset {
    const message = createBaseUserMarketplaceDataset();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.createdAt = object.createdAt ?? undefined;
    message.purchasePriceCents = object.purchasePriceCents ?? 0;
    message.purchaseTransactionId = object.purchaseTransactionId ?? "";
    return message;
  },
};

function createBaseGetUserMarketplaceDatasetsResponse(): GetUserMarketplaceDatasetsResponse {
  return { userDatasets: [] };
}

export const GetUserMarketplaceDatasetsResponse: MessageFns<GetUserMarketplaceDatasetsResponse> =
  {
    encode(
      message: GetUserMarketplaceDatasetsResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.userDatasets) {
        UserMarketplaceDataset.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetUserMarketplaceDatasetsResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetUserMarketplaceDatasetsResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.userDatasets.push(
              UserMarketplaceDataset.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetUserMarketplaceDatasetsResponse {
      return {
        userDatasets: globalThis.Array.isArray(object?.userDatasets)
          ? object.userDatasets.map((e: any) =>
              UserMarketplaceDataset.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetUserMarketplaceDatasetsResponse): unknown {
      const obj: any = {};
      if (message.userDatasets?.length) {
        obj.userDatasets = message.userDatasets.map(e =>
          UserMarketplaceDataset.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetUserMarketplaceDatasetsResponse>,
    ): GetUserMarketplaceDatasetsResponse {
      return GetUserMarketplaceDatasetsResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetUserMarketplaceDatasetsResponse>,
    ): GetUserMarketplaceDatasetsResponse {
      const message = createBaseGetUserMarketplaceDatasetsResponse();
      message.userDatasets =
        object.userDatasets?.map(e => UserMarketplaceDataset.fromPartial(e)) ||
        [];
      return message;
    },
  };

function createBaseUpsertHotkeysRequest(): UpsertHotkeysRequest {
  return { hotkeys: [] };
}

export const UpsertHotkeysRequest: MessageFns<UpsertHotkeysRequest> = {
  encode(
    message: UpsertHotkeysRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.hotkeys) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpsertHotkeysRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertHotkeysRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.hotkeys.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertHotkeysRequest {
    return {
      hotkeys: globalThis.Array.isArray(object?.hotkeys)
        ? object.hotkeys.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: UpsertHotkeysRequest): unknown {
    const obj: any = {};
    if (message.hotkeys?.length) {
      obj.hotkeys = message.hotkeys;
    }
    return obj;
  },

  create(base?: DeepPartial<UpsertHotkeysRequest>): UpsertHotkeysRequest {
    return UpsertHotkeysRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpsertHotkeysRequest>): UpsertHotkeysRequest {
    const message = createBaseUpsertHotkeysRequest();
    message.hotkeys = object.hotkeys?.map(e => e) || [];
    return message;
  },
};

function createBaseUpsertMarketplaceTaskSuggestionsRequest(): UpsertMarketplaceTaskSuggestionsRequest {
  return { gravityTaskId: "", suggestedGravityTaskIds: [] };
}

export const UpsertMarketplaceTaskSuggestionsRequest: MessageFns<UpsertMarketplaceTaskSuggestionsRequest> =
  {
    encode(
      message: UpsertMarketplaceTaskSuggestionsRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      for (const v of message.suggestedGravityTaskIds) {
        writer.uint32(18).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): UpsertMarketplaceTaskSuggestionsRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseUpsertMarketplaceTaskSuggestionsRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.suggestedGravityTaskIds.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): UpsertMarketplaceTaskSuggestionsRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
        suggestedGravityTaskIds: globalThis.Array.isArray(
          object?.suggestedGravityTaskIds,
        )
          ? object.suggestedGravityTaskIds.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: UpsertMarketplaceTaskSuggestionsRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      if (message.suggestedGravityTaskIds?.length) {
        obj.suggestedGravityTaskIds = message.suggestedGravityTaskIds;
      }
      return obj;
    },

    create(
      base?: DeepPartial<UpsertMarketplaceTaskSuggestionsRequest>,
    ): UpsertMarketplaceTaskSuggestionsRequest {
      return UpsertMarketplaceTaskSuggestionsRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<UpsertMarketplaceTaskSuggestionsRequest>,
    ): UpsertMarketplaceTaskSuggestionsRequest {
      const message = createBaseUpsertMarketplaceTaskSuggestionsRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      message.suggestedGravityTaskIds =
        object.suggestedGravityTaskIds?.map(e => e) || [];
      return message;
    },
  };

function createBaseGetMarketplaceTaskSuggestionsRequest(): GetMarketplaceTaskSuggestionsRequest {
  return { gravityTaskId: "" };
}

export const GetMarketplaceTaskSuggestionsRequest: MessageFns<GetMarketplaceTaskSuggestionsRequest> =
  {
    encode(
      message: GetMarketplaceTaskSuggestionsRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetMarketplaceTaskSuggestionsRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetMarketplaceTaskSuggestionsRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetMarketplaceTaskSuggestionsRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
      };
    },

    toJSON(message: GetMarketplaceTaskSuggestionsRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetMarketplaceTaskSuggestionsRequest>,
    ): GetMarketplaceTaskSuggestionsRequest {
      return GetMarketplaceTaskSuggestionsRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetMarketplaceTaskSuggestionsRequest>,
    ): GetMarketplaceTaskSuggestionsRequest {
      const message = createBaseGetMarketplaceTaskSuggestionsRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      return message;
    },
  };

function createBaseGetMarketplaceTaskSuggestionsResponse(): GetMarketplaceTaskSuggestionsResponse {
  return { suggestedGravityTaskIds: [] };
}

export const GetMarketplaceTaskSuggestionsResponse: MessageFns<GetMarketplaceTaskSuggestionsResponse> =
  {
    encode(
      message: GetMarketplaceTaskSuggestionsResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.suggestedGravityTaskIds) {
        writer.uint32(10).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetMarketplaceTaskSuggestionsResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetMarketplaceTaskSuggestionsResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.suggestedGravityTaskIds.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetMarketplaceTaskSuggestionsResponse {
      return {
        suggestedGravityTaskIds: globalThis.Array.isArray(
          object?.suggestedGravityTaskIds,
        )
          ? object.suggestedGravityTaskIds.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: GetMarketplaceTaskSuggestionsResponse): unknown {
      const obj: any = {};
      if (message.suggestedGravityTaskIds?.length) {
        obj.suggestedGravityTaskIds = message.suggestedGravityTaskIds;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetMarketplaceTaskSuggestionsResponse>,
    ): GetMarketplaceTaskSuggestionsResponse {
      return GetMarketplaceTaskSuggestionsResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetMarketplaceTaskSuggestionsResponse>,
    ): GetMarketplaceTaskSuggestionsResponse {
      const message = createBaseGetMarketplaceTaskSuggestionsResponse();
      message.suggestedGravityTaskIds =
        object.suggestedGravityTaskIds?.map(e => e) || [];
      return message;
    },
  };

function createBasePopularTag(): PopularTag {
  return { tag: "", count: 0 };
}

export const PopularTag: MessageFns<PopularTag> = {
  encode(
    message: PopularTag,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.tag !== "") {
      writer.uint32(10).string(message.tag);
    }
    if (message.count !== 0) {
      writer.uint32(16).uint64(message.count);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PopularTag {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePopularTag();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.tag = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.count = longToNumber(reader.uint64());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PopularTag {
    return {
      tag: isSet(object.tag) ? globalThis.String(object.tag) : "",
      count: isSet(object.count) ? globalThis.Number(object.count) : 0,
    };
  },

  toJSON(message: PopularTag): unknown {
    const obj: any = {};
    if (message.tag !== "") {
      obj.tag = message.tag;
    }
    if (message.count !== 0) {
      obj.count = Math.round(message.count);
    }
    return obj;
  },

  create(base?: DeepPartial<PopularTag>): PopularTag {
    return PopularTag.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PopularTag>): PopularTag {
    const message = createBasePopularTag();
    message.tag = object.tag ?? "";
    message.count = object.count ?? 0;
    return message;
  },
};

function createBaseGetPopularTagsResponse(): GetPopularTagsResponse {
  return { popularTags: [] };
}

export const GetPopularTagsResponse: MessageFns<GetPopularTagsResponse> = {
  encode(
    message: GetPopularTagsResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.popularTags) {
      PopularTag.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetPopularTagsResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetPopularTagsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.popularTags.push(PopularTag.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetPopularTagsResponse {
    return {
      popularTags: globalThis.Array.isArray(object?.popularTags)
        ? object.popularTags.map((e: any) => PopularTag.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GetPopularTagsResponse): unknown {
    const obj: any = {};
    if (message.popularTags?.length) {
      obj.popularTags = message.popularTags.map(e => PopularTag.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<GetPopularTagsResponse>): GetPopularTagsResponse {
    return GetPopularTagsResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GetPopularTagsResponse>,
  ): GetPopularTagsResponse {
    const message = createBaseGetPopularTagsResponse();
    message.popularTags =
      object.popularTags?.map(e => PopularTag.fromPartial(e)) || [];
    return message;
  },
};

function createBasePublishDatasetRequest(): PublishDatasetRequest {
  return { datasetId: "" };
}

export const PublishDatasetRequest: MessageFns<PublishDatasetRequest> = {
  encode(
    message: PublishDatasetRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): PublishDatasetRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePublishDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PublishDatasetRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
    };
  },

  toJSON(message: PublishDatasetRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    return obj;
  },

  create(base?: DeepPartial<PublishDatasetRequest>): PublishDatasetRequest {
    return PublishDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PublishDatasetRequest>,
  ): PublishDatasetRequest {
    const message = createBasePublishDatasetRequest();
    message.datasetId = object.datasetId ?? "";
    return message;
  },
};

function createBasePersistentDatasetWorkflow(): PersistentDatasetWorkflow {
  return { datasetId: "", status: "" };
}

export const PersistentDatasetWorkflow: MessageFns<PersistentDatasetWorkflow> =
  {
    encode(
      message: PersistentDatasetWorkflow,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.datasetId !== "") {
        writer.uint32(10).string(message.datasetId);
      }
      if (message.status !== "") {
        writer.uint32(18).string(message.status);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): PersistentDatasetWorkflow {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBasePersistentDatasetWorkflow();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.datasetId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.status = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): PersistentDatasetWorkflow {
      return {
        datasetId: isSet(object.datasetId)
          ? globalThis.String(object.datasetId)
          : "",
        status: isSet(object.status) ? globalThis.String(object.status) : "",
      };
    },

    toJSON(message: PersistentDatasetWorkflow): unknown {
      const obj: any = {};
      if (message.datasetId !== "") {
        obj.datasetId = message.datasetId;
      }
      if (message.status !== "") {
        obj.status = message.status;
      }
      return obj;
    },

    create(
      base?: DeepPartial<PersistentDatasetWorkflow>,
    ): PersistentDatasetWorkflow {
      return PersistentDatasetWorkflow.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<PersistentDatasetWorkflow>,
    ): PersistentDatasetWorkflow {
      const message = createBasePersistentDatasetWorkflow();
      message.datasetId = object.datasetId ?? "";
      message.status = object.status ?? "";
      return message;
    },
  };

function createBaseAddPersistentDatasetWorkflowsRequest(): AddPersistentDatasetWorkflowsRequest {
  return { datasetWorkflows: [] };
}

export const AddPersistentDatasetWorkflowsRequest: MessageFns<AddPersistentDatasetWorkflowsRequest> =
  {
    encode(
      message: AddPersistentDatasetWorkflowsRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.datasetWorkflows) {
        PersistentDatasetWorkflow.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): AddPersistentDatasetWorkflowsRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseAddPersistentDatasetWorkflowsRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.datasetWorkflows.push(
              PersistentDatasetWorkflow.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): AddPersistentDatasetWorkflowsRequest {
      return {
        datasetWorkflows: globalThis.Array.isArray(object?.datasetWorkflows)
          ? object.datasetWorkflows.map((e: any) =>
              PersistentDatasetWorkflow.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: AddPersistentDatasetWorkflowsRequest): unknown {
      const obj: any = {};
      if (message.datasetWorkflows?.length) {
        obj.datasetWorkflows = message.datasetWorkflows.map(e =>
          PersistentDatasetWorkflow.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<AddPersistentDatasetWorkflowsRequest>,
    ): AddPersistentDatasetWorkflowsRequest {
      return AddPersistentDatasetWorkflowsRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<AddPersistentDatasetWorkflowsRequest>,
    ): AddPersistentDatasetWorkflowsRequest {
      const message = createBaseAddPersistentDatasetWorkflowsRequest();
      message.datasetWorkflows =
        object.datasetWorkflows?.map(e =>
          PersistentDatasetWorkflow.fromPartial(e),
        ) || [];
      return message;
    },
  };

function createBaseUpsertMarketplaceTaskMetadataRequest(): UpsertMarketplaceTaskMetadataRequest {
  return {
    gravityTaskId: "",
    description: "",
    name: "",
    imageUrl: "",
    tags: [],
  };
}

export const UpsertMarketplaceTaskMetadataRequest: MessageFns<UpsertMarketplaceTaskMetadataRequest> =
  {
    encode(
      message: UpsertMarketplaceTaskMetadataRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      if (message.description !== "") {
        writer.uint32(18).string(message.description);
      }
      if (message.name !== "") {
        writer.uint32(26).string(message.name);
      }
      if (message.imageUrl !== "") {
        writer.uint32(34).string(message.imageUrl);
      }
      for (const v of message.tags) {
        writer.uint32(42).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): UpsertMarketplaceTaskMetadataRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseUpsertMarketplaceTaskMetadataRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.description = reader.string();
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.name = reader.string();
            continue;
          }
          case 4: {
            if (tag !== 34) {
              break;
            }

            message.imageUrl = reader.string();
            continue;
          }
          case 5: {
            if (tag !== 42) {
              break;
            }

            message.tags.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): UpsertMarketplaceTaskMetadataRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
        description: isSet(object.description)
          ? globalThis.String(object.description)
          : "",
        name: isSet(object.name) ? globalThis.String(object.name) : "",
        imageUrl: isSet(object.imageUrl)
          ? globalThis.String(object.imageUrl)
          : "",
        tags: globalThis.Array.isArray(object?.tags)
          ? object.tags.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: UpsertMarketplaceTaskMetadataRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      if (message.description !== "") {
        obj.description = message.description;
      }
      if (message.name !== "") {
        obj.name = message.name;
      }
      if (message.imageUrl !== "") {
        obj.imageUrl = message.imageUrl;
      }
      if (message.tags?.length) {
        obj.tags = message.tags;
      }
      return obj;
    },

    create(
      base?: DeepPartial<UpsertMarketplaceTaskMetadataRequest>,
    ): UpsertMarketplaceTaskMetadataRequest {
      return UpsertMarketplaceTaskMetadataRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<UpsertMarketplaceTaskMetadataRequest>,
    ): UpsertMarketplaceTaskMetadataRequest {
      const message = createBaseUpsertMarketplaceTaskMetadataRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      message.description = object.description ?? "";
      message.name = object.name ?? "";
      message.imageUrl = object.imageUrl ?? "";
      message.tags = object.tags?.map(e => e) || [];
      return message;
    },
  };

function createBaseGetMarketplaceDatasetsRequest(): GetMarketplaceDatasetsRequest {
  return { popular: false };
}

export const GetMarketplaceDatasetsRequest: MessageFns<GetMarketplaceDatasetsRequest> =
  {
    encode(
      message: GetMarketplaceDatasetsRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.popular !== false) {
        writer.uint32(8).bool(message.popular);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetMarketplaceDatasetsRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetMarketplaceDatasetsRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 8) {
              break;
            }

            message.popular = reader.bool();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetMarketplaceDatasetsRequest {
      return {
        popular: isSet(object.popular)
          ? globalThis.Boolean(object.popular)
          : false,
      };
    },

    toJSON(message: GetMarketplaceDatasetsRequest): unknown {
      const obj: any = {};
      if (message.popular !== false) {
        obj.popular = message.popular;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetMarketplaceDatasetsRequest>,
    ): GetMarketplaceDatasetsRequest {
      return GetMarketplaceDatasetsRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetMarketplaceDatasetsRequest>,
    ): GetMarketplaceDatasetsRequest {
      const message = createBaseGetMarketplaceDatasetsRequest();
      message.popular = object.popular ?? false;
      return message;
    },
  };

function createBaseGetPersistentDatasetWorkflowsResponse(): GetPersistentDatasetWorkflowsResponse {
  return { datasetWorkflows: [] };
}

export const GetPersistentDatasetWorkflowsResponse: MessageFns<GetPersistentDatasetWorkflowsResponse> =
  {
    encode(
      message: GetPersistentDatasetWorkflowsResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.datasetWorkflows) {
        PersistentDatasetWorkflow.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetPersistentDatasetWorkflowsResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetPersistentDatasetWorkflowsResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.datasetWorkflows.push(
              PersistentDatasetWorkflow.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetPersistentDatasetWorkflowsResponse {
      return {
        datasetWorkflows: globalThis.Array.isArray(object?.datasetWorkflows)
          ? object.datasetWorkflows.map((e: any) =>
              PersistentDatasetWorkflow.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetPersistentDatasetWorkflowsResponse): unknown {
      const obj: any = {};
      if (message.datasetWorkflows?.length) {
        obj.datasetWorkflows = message.datasetWorkflows.map(e =>
          PersistentDatasetWorkflow.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetPersistentDatasetWorkflowsResponse>,
    ): GetPersistentDatasetWorkflowsResponse {
      return GetPersistentDatasetWorkflowsResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetPersistentDatasetWorkflowsResponse>,
    ): GetPersistentDatasetWorkflowsResponse {
      const message = createBaseGetPersistentDatasetWorkflowsResponse();
      message.datasetWorkflows =
        object.datasetWorkflows?.map(e =>
          PersistentDatasetWorkflow.fromPartial(e),
        ) || [];
      return message;
    },
  };

function createBaseCrawler(): Crawler {
  return {
    crawlerId: "",
    criteria: undefined,
    startTime: undefined,
    deregistrationTime: undefined,
    archiveTime: undefined,
    state: undefined,
    datasetWorkflows: [],
    parquetPaths: [],
  };
}

export const Crawler: MessageFns<Crawler> = {
  encode(
    message: Crawler,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    if (message.criteria !== undefined) {
      CrawlerCriteria.encode(message.criteria, writer.uint32(18).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.startTime),
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.deregistrationTime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.deregistrationTime),
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.archiveTime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.archiveTime),
        writer.uint32(42).fork(),
      ).join();
    }
    if (message.state !== undefined) {
      CrawlerState.encode(message.state, writer.uint32(50).fork()).join();
    }
    for (const v of message.datasetWorkflows) {
      writer.uint32(58).string(v!);
    }
    for (const v of message.parquetPaths) {
      writer.uint32(66).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Crawler {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawler();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.criteria = CrawlerCriteria.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.deregistrationTime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.archiveTime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.state = CrawlerState.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.datasetWorkflows.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.parquetPaths.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Crawler {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
      criteria: isSet(object.criteria)
        ? CrawlerCriteria.fromJSON(object.criteria)
        : undefined,
      startTime: isSet(object.startTime)
        ? fromJsonTimestamp(object.startTime)
        : undefined,
      deregistrationTime: isSet(object.deregistrationTime)
        ? fromJsonTimestamp(object.deregistrationTime)
        : undefined,
      archiveTime: isSet(object.archiveTime)
        ? fromJsonTimestamp(object.archiveTime)
        : undefined,
      state: isSet(object.state)
        ? CrawlerState.fromJSON(object.state)
        : undefined,
      datasetWorkflows: globalThis.Array.isArray(object?.datasetWorkflows)
        ? object.datasetWorkflows.map((e: any) => globalThis.String(e))
        : [],
      parquetPaths: globalThis.Array.isArray(object?.parquetPaths)
        ? object.parquetPaths.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Crawler): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    if (message.criteria !== undefined) {
      obj.criteria = CrawlerCriteria.toJSON(message.criteria);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.deregistrationTime !== undefined) {
      obj.deregistrationTime = message.deregistrationTime.toISOString();
    }
    if (message.archiveTime !== undefined) {
      obj.archiveTime = message.archiveTime.toISOString();
    }
    if (message.state !== undefined) {
      obj.state = CrawlerState.toJSON(message.state);
    }
    if (message.datasetWorkflows?.length) {
      obj.datasetWorkflows = message.datasetWorkflows;
    }
    if (message.parquetPaths?.length) {
      obj.parquetPaths = message.parquetPaths;
    }
    return obj;
  },

  create(base?: DeepPartial<Crawler>): Crawler {
    return Crawler.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Crawler>): Crawler {
    const message = createBaseCrawler();
    message.crawlerId = object.crawlerId ?? "";
    message.criteria =
      object.criteria !== undefined && object.criteria !== null
        ? CrawlerCriteria.fromPartial(object.criteria)
        : undefined;
    message.startTime = object.startTime ?? undefined;
    message.deregistrationTime = object.deregistrationTime ?? undefined;
    message.archiveTime = object.archiveTime ?? undefined;
    message.state =
      object.state !== undefined && object.state !== null
        ? CrawlerState.fromPartial(object.state)
        : undefined;
    message.datasetWorkflows = object.datasetWorkflows?.map(e => e) || [];
    message.parquetPaths = object.parquetPaths?.map(e => e) || [];
    return message;
  },
};

function createBasePersistentGravityTask(): PersistentGravityTask {
  return { gravityTaskId: "", ingestDt: "" };
}

export const PersistentGravityTask: MessageFns<PersistentGravityTask> = {
  encode(
    message: PersistentGravityTask,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    if (message.ingestDt !== "") {
      writer.uint32(18).string(message.ingestDt);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): PersistentGravityTask {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePersistentGravityTask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.ingestDt = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PersistentGravityTask {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      ingestDt: isSet(object.ingestDt)
        ? globalThis.String(object.ingestDt)
        : "",
    };
  },

  toJSON(message: PersistentGravityTask): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.ingestDt !== "") {
      obj.ingestDt = message.ingestDt;
    }
    return obj;
  },

  create(base?: DeepPartial<PersistentGravityTask>): PersistentGravityTask {
    return PersistentGravityTask.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PersistentGravityTask>,
  ): PersistentGravityTask {
    const message = createBasePersistentGravityTask();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.ingestDt = object.ingestDt ?? "";
    return message;
  },
};

function createBaseGetPersistentGravityTasksResponse(): GetPersistentGravityTasksResponse {
  return { persistentGravityTasks: [] };
}

export const GetPersistentGravityTasksResponse: MessageFns<GetPersistentGravityTasksResponse> =
  {
    encode(
      message: GetPersistentGravityTasksResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.persistentGravityTasks) {
        PersistentGravityTask.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetPersistentGravityTasksResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetPersistentGravityTasksResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.persistentGravityTasks.push(
              PersistentGravityTask.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetPersistentGravityTasksResponse {
      return {
        persistentGravityTasks: globalThis.Array.isArray(
          object?.persistentGravityTasks,
        )
          ? object.persistentGravityTasks.map((e: any) =>
              PersistentGravityTask.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetPersistentGravityTasksResponse): unknown {
      const obj: any = {};
      if (message.persistentGravityTasks?.length) {
        obj.persistentGravityTasks = message.persistentGravityTasks.map(e =>
          PersistentGravityTask.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetPersistentGravityTasksResponse>,
    ): GetPersistentGravityTasksResponse {
      return GetPersistentGravityTasksResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetPersistentGravityTasksResponse>,
    ): GetPersistentGravityTasksResponse {
      const message = createBaseGetPersistentGravityTasksResponse();
      message.persistentGravityTasks =
        object.persistentGravityTasks?.map(e =>
          PersistentGravityTask.fromPartial(e),
        ) || [];
      return message;
    },
  };

function createBaseUpsertCrawlerRequest(): UpsertCrawlerRequest {
  return { gravityTaskId: "", crawler: undefined };
}

export const UpsertCrawlerRequest: MessageFns<UpsertCrawlerRequest> = {
  encode(
    message: UpsertCrawlerRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    if (message.crawler !== undefined) {
      Crawler.encode(message.crawler, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpsertCrawlerRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertCrawlerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.crawler = Crawler.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertCrawlerRequest {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      crawler: isSet(object.crawler)
        ? Crawler.fromJSON(object.crawler)
        : undefined,
    };
  },

  toJSON(message: UpsertCrawlerRequest): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.crawler !== undefined) {
      obj.crawler = Crawler.toJSON(message.crawler);
    }
    return obj;
  },

  create(base?: DeepPartial<UpsertCrawlerRequest>): UpsertCrawlerRequest {
    return UpsertCrawlerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpsertCrawlerRequest>): UpsertCrawlerRequest {
    const message = createBaseUpsertCrawlerRequest();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.crawler =
      object.crawler !== undefined && object.crawler !== null
        ? Crawler.fromPartial(object.crawler)
        : undefined;
    return message;
  },
};

function createBaseUpsertResponse(): UpsertResponse {
  return { message: "" };
}

export const UpsertResponse: MessageFns<UpsertResponse> = {
  encode(
    message: UpsertResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpsertResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertResponse {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: UpsertResponse): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<UpsertResponse>): UpsertResponse {
    return UpsertResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpsertResponse>): UpsertResponse {
    const message = createBaseUpsertResponse();
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseUpsertGravityTaskRequest(): UpsertGravityTaskRequest {
  return { gravityTask: undefined };
}

export const UpsertGravityTaskRequest: MessageFns<UpsertGravityTaskRequest> = {
  encode(
    message: UpsertGravityTaskRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTask !== undefined) {
      GravityTaskRequest.encode(
        message.gravityTask,
        writer.uint32(10).fork(),
      ).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpsertGravityTaskRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertGravityTaskRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTask = GravityTaskRequest.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertGravityTaskRequest {
    return {
      gravityTask: isSet(object.gravityTask)
        ? GravityTaskRequest.fromJSON(object.gravityTask)
        : undefined,
    };
  },

  toJSON(message: UpsertGravityTaskRequest): unknown {
    const obj: any = {};
    if (message.gravityTask !== undefined) {
      obj.gravityTask = GravityTaskRequest.toJSON(message.gravityTask);
    }
    return obj;
  },

  create(
    base?: DeepPartial<UpsertGravityTaskRequest>,
  ): UpsertGravityTaskRequest {
    return UpsertGravityTaskRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<UpsertGravityTaskRequest>,
  ): UpsertGravityTaskRequest {
    const message = createBaseUpsertGravityTaskRequest();
    message.gravityTask =
      object.gravityTask !== undefined && object.gravityTask !== null
        ? GravityTaskRequest.fromPartial(object.gravityTask)
        : undefined;
    return message;
  },
};

function createBaseUpsertGravityTaskResponse(): UpsertGravityTaskResponse {
  return { message: "" };
}

export const UpsertGravityTaskResponse: MessageFns<UpsertGravityTaskResponse> =
  {
    encode(
      message: UpsertGravityTaskResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.message !== "") {
        writer.uint32(10).string(message.message);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): UpsertGravityTaskResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseUpsertGravityTaskResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.message = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): UpsertGravityTaskResponse {
      return {
        message: isSet(object.message) ? globalThis.String(object.message) : "",
      };
    },

    toJSON(message: UpsertGravityTaskResponse): unknown {
      const obj: any = {};
      if (message.message !== "") {
        obj.message = message.message;
      }
      return obj;
    },

    create(
      base?: DeepPartial<UpsertGravityTaskResponse>,
    ): UpsertGravityTaskResponse {
      return UpsertGravityTaskResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<UpsertGravityTaskResponse>,
    ): UpsertGravityTaskResponse {
      const message = createBaseUpsertGravityTaskResponse();
      message.message = object.message ?? "";
      return message;
    },
  };

function createBaseGravityTaskRequest(): GravityTaskRequest {
  return {
    id: "",
    name: "",
    status: "",
    startTime: undefined,
    notificationTo: "",
    notificationLink: "",
  };
}

export const GravityTaskRequest: MessageFns<GravityTaskRequest> = {
  encode(
    message: GravityTaskRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    if (message.status !== "") {
      writer.uint32(26).string(message.status);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.startTime),
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.notificationTo !== "") {
      writer.uint32(42).string(message.notificationTo);
    }
    if (message.notificationLink !== "") {
      writer.uint32(50).string(message.notificationLink);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GravityTaskRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGravityTaskRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.notificationTo = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.notificationLink = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GravityTaskRequest {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      startTime: isSet(object.startTime)
        ? fromJsonTimestamp(object.startTime)
        : undefined,
      notificationTo: isSet(object.notificationTo)
        ? globalThis.String(object.notificationTo)
        : "",
      notificationLink: isSet(object.notificationLink)
        ? globalThis.String(object.notificationLink)
        : "",
    };
  },

  toJSON(message: GravityTaskRequest): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.notificationTo !== "") {
      obj.notificationTo = message.notificationTo;
    }
    if (message.notificationLink !== "") {
      obj.notificationLink = message.notificationLink;
    }
    return obj;
  },

  create(base?: DeepPartial<GravityTaskRequest>): GravityTaskRequest {
    return GravityTaskRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GravityTaskRequest>): GravityTaskRequest {
    const message = createBaseGravityTaskRequest();
    message.id = object.id ?? "";
    message.name = object.name ?? "";
    message.status = object.status ?? "";
    message.startTime = object.startTime ?? undefined;
    message.notificationTo = object.notificationTo ?? "";
    message.notificationLink = object.notificationLink ?? "";
    return message;
  },
};

function createBaseInsertCrawlerCriteriaRequest(): InsertCrawlerCriteriaRequest {
  return { crawlerId: "", crawlerCriteria: undefined };
}

export const InsertCrawlerCriteriaRequest: MessageFns<InsertCrawlerCriteriaRequest> =
  {
    encode(
      message: InsertCrawlerCriteriaRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.crawlerId !== "") {
        writer.uint32(10).string(message.crawlerId);
      }
      if (message.crawlerCriteria !== undefined) {
        CrawlerCriteria.encode(
          message.crawlerCriteria,
          writer.uint32(18).fork(),
        ).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): InsertCrawlerCriteriaRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseInsertCrawlerCriteriaRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.crawlerId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.crawlerCriteria = CrawlerCriteria.decode(
              reader,
              reader.uint32(),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): InsertCrawlerCriteriaRequest {
      return {
        crawlerId: isSet(object.crawlerId)
          ? globalThis.String(object.crawlerId)
          : "",
        crawlerCriteria: isSet(object.crawlerCriteria)
          ? CrawlerCriteria.fromJSON(object.crawlerCriteria)
          : undefined,
      };
    },

    toJSON(message: InsertCrawlerCriteriaRequest): unknown {
      const obj: any = {};
      if (message.crawlerId !== "") {
        obj.crawlerId = message.crawlerId;
      }
      if (message.crawlerCriteria !== undefined) {
        obj.crawlerCriteria = CrawlerCriteria.toJSON(message.crawlerCriteria);
      }
      return obj;
    },

    create(
      base?: DeepPartial<InsertCrawlerCriteriaRequest>,
    ): InsertCrawlerCriteriaRequest {
      return InsertCrawlerCriteriaRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<InsertCrawlerCriteriaRequest>,
    ): InsertCrawlerCriteriaRequest {
      const message = createBaseInsertCrawlerCriteriaRequest();
      message.crawlerId = object.crawlerId ?? "";
      message.crawlerCriteria =
        object.crawlerCriteria !== undefined && object.crawlerCriteria !== null
          ? CrawlerCriteria.fromPartial(object.crawlerCriteria)
          : undefined;
      return message;
    },
  };

function createBaseCrawlerCriteria(): CrawlerCriteria {
  return {
    platform: "",
    topic: undefined,
    notification: undefined,
    mock: false,
    userId: "",
    keyword: undefined,
    postStartDatetime: undefined,
    postEndDatetime: undefined,
  };
}

export const CrawlerCriteria: MessageFns<CrawlerCriteria> = {
  encode(
    message: CrawlerCriteria,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.platform !== "") {
      writer.uint32(10).string(message.platform);
    }
    if (message.topic !== undefined) {
      writer.uint32(18).string(message.topic);
    }
    if (message.notification !== undefined) {
      CrawlerNotification.encode(
        message.notification,
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.mock !== false) {
      writer.uint32(32).bool(message.mock);
    }
    if (message.userId !== "") {
      writer.uint32(42).string(message.userId);
    }
    if (message.keyword !== undefined) {
      writer.uint32(50).string(message.keyword);
    }
    if (message.postStartDatetime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.postStartDatetime),
        writer.uint32(58).fork(),
      ).join();
    }
    if (message.postEndDatetime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.postEndDatetime),
        writer.uint32(66).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CrawlerCriteria {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerCriteria();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.platform = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.notification = CrawlerNotification.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.mock = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.userId = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.keyword = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.postStartDatetime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.postEndDatetime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerCriteria {
    return {
      platform: isSet(object.platform)
        ? globalThis.String(object.platform)
        : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : undefined,
      notification: isSet(object.notification)
        ? CrawlerNotification.fromJSON(object.notification)
        : undefined,
      mock: isSet(object.mock) ? globalThis.Boolean(object.mock) : false,
      userId: isSet(object.userId) ? globalThis.String(object.userId) : "",
      keyword: isSet(object.keyword)
        ? globalThis.String(object.keyword)
        : undefined,
      postStartDatetime: isSet(object.postStartDatetime)
        ? fromJsonTimestamp(object.postStartDatetime)
        : undefined,
      postEndDatetime: isSet(object.postEndDatetime)
        ? fromJsonTimestamp(object.postEndDatetime)
        : undefined,
    };
  },

  toJSON(message: CrawlerCriteria): unknown {
    const obj: any = {};
    if (message.platform !== "") {
      obj.platform = message.platform;
    }
    if (message.topic !== undefined) {
      obj.topic = message.topic;
    }
    if (message.notification !== undefined) {
      obj.notification = CrawlerNotification.toJSON(message.notification);
    }
    if (message.mock !== false) {
      obj.mock = message.mock;
    }
    if (message.userId !== "") {
      obj.userId = message.userId;
    }
    if (message.keyword !== undefined) {
      obj.keyword = message.keyword;
    }
    if (message.postStartDatetime !== undefined) {
      obj.postStartDatetime = message.postStartDatetime.toISOString();
    }
    if (message.postEndDatetime !== undefined) {
      obj.postEndDatetime = message.postEndDatetime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerCriteria>): CrawlerCriteria {
    return CrawlerCriteria.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerCriteria>): CrawlerCriteria {
    const message = createBaseCrawlerCriteria();
    message.platform = object.platform ?? "";
    message.topic = object.topic ?? undefined;
    message.notification =
      object.notification !== undefined && object.notification !== null
        ? CrawlerNotification.fromPartial(object.notification)
        : undefined;
    message.mock = object.mock ?? false;
    message.userId = object.userId ?? "";
    message.keyword = object.keyword ?? undefined;
    message.postStartDatetime = object.postStartDatetime ?? undefined;
    message.postEndDatetime = object.postEndDatetime ?? undefined;
    return message;
  },
};

function createBasePersistentTopic(): PersistentTopic {
  return { platform: "", topic: undefined };
}

export const PersistentTopic: MessageFns<PersistentTopic> = {
  encode(
    message: PersistentTopic,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.platform !== "") {
      writer.uint32(10).string(message.platform);
    }
    if (message.topic !== undefined) {
      writer.uint32(18).string(message.topic);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PersistentTopic {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePersistentTopic();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.platform = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.topic = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PersistentTopic {
    return {
      platform: isSet(object.platform)
        ? globalThis.String(object.platform)
        : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : undefined,
    };
  },

  toJSON(message: PersistentTopic): unknown {
    const obj: any = {};
    if (message.platform !== "") {
      obj.platform = message.platform;
    }
    if (message.topic !== undefined) {
      obj.topic = message.topic;
    }
    return obj;
  },

  create(base?: DeepPartial<PersistentTopic>): PersistentTopic {
    return PersistentTopic.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<PersistentTopic>): PersistentTopic {
    const message = createBasePersistentTopic();
    message.platform = object.platform ?? "";
    message.topic = object.topic ?? undefined;
    return message;
  },
};

function createBasePersistentTopicResponse(): PersistentTopicResponse {
  return { persistentTopics: [] };
}

export const PersistentTopicResponse: MessageFns<PersistentTopicResponse> = {
  encode(
    message: PersistentTopicResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.persistentTopics) {
      PersistentTopic.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): PersistentTopicResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePersistentTopicResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.persistentTopics.push(
            PersistentTopic.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PersistentTopicResponse {
    return {
      persistentTopics: globalThis.Array.isArray(object?.persistentTopics)
        ? object.persistentTopics.map((e: any) => PersistentTopic.fromJSON(e))
        : [],
    };
  },

  toJSON(message: PersistentTopicResponse): unknown {
    const obj: any = {};
    if (message.persistentTopics?.length) {
      obj.persistentTopics = message.persistentTopics.map(e =>
        PersistentTopic.toJSON(e),
      );
    }
    return obj;
  },

  create(base?: DeepPartial<PersistentTopicResponse>): PersistentTopicResponse {
    return PersistentTopicResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<PersistentTopicResponse>,
  ): PersistentTopicResponse {
    const message = createBasePersistentTopicResponse();
    message.persistentTopics =
      object.persistentTopics?.map(e => PersistentTopic.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCrawlerNotification(): CrawlerNotification {
  return { to: "", link: "" };
}

export const CrawlerNotification: MessageFns<CrawlerNotification> = {
  encode(
    message: CrawlerNotification,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.to !== "") {
      writer.uint32(10).string(message.to);
    }
    if (message.link !== "") {
      writer.uint32(18).string(message.link);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CrawlerNotification {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerNotification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.to = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.link = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerNotification {
    return {
      to: isSet(object.to) ? globalThis.String(object.to) : "",
      link: isSet(object.link) ? globalThis.String(object.link) : "",
    };
  },

  toJSON(message: CrawlerNotification): unknown {
    const obj: any = {};
    if (message.to !== "") {
      obj.to = message.to;
    }
    if (message.link !== "") {
      obj.link = message.link;
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerNotification>): CrawlerNotification {
    return CrawlerNotification.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerNotification>): CrawlerNotification {
    const message = createBaseCrawlerNotification();
    message.to = object.to ?? "";
    message.link = object.link ?? "";
    return message;
  },
};

function createBaseHfRepo(): HfRepo {
  return { repoName: "", rowCount: 0, lastUpdate: "" };
}

export const HfRepo: MessageFns<HfRepo> = {
  encode(
    message: HfRepo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.repoName !== "") {
      writer.uint32(10).string(message.repoName);
    }
    if (message.rowCount !== 0) {
      writer.uint32(16).uint64(message.rowCount);
    }
    if (message.lastUpdate !== "") {
      writer.uint32(26).string(message.lastUpdate);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HfRepo {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHfRepo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.repoName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.rowCount = longToNumber(reader.uint64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.lastUpdate = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HfRepo {
    return {
      repoName: isSet(object.repoName)
        ? globalThis.String(object.repoName)
        : "",
      rowCount: isSet(object.rowCount) ? globalThis.Number(object.rowCount) : 0,
      lastUpdate: isSet(object.lastUpdate)
        ? globalThis.String(object.lastUpdate)
        : "",
    };
  },

  toJSON(message: HfRepo): unknown {
    const obj: any = {};
    if (message.repoName !== "") {
      obj.repoName = message.repoName;
    }
    if (message.rowCount !== 0) {
      obj.rowCount = Math.round(message.rowCount);
    }
    if (message.lastUpdate !== "") {
      obj.lastUpdate = message.lastUpdate;
    }
    return obj;
  },

  create(base?: DeepPartial<HfRepo>): HfRepo {
    return HfRepo.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<HfRepo>): HfRepo {
    const message = createBaseHfRepo();
    message.repoName = object.repoName ?? "";
    message.rowCount = object.rowCount ?? 0;
    message.lastUpdate = object.lastUpdate ?? "";
    return message;
  },
};

function createBaseCrawlerState(): CrawlerState {
  return { status: "", bytesCollected: 0, recordsCollected: 0, repos: [] };
}

export const CrawlerState: MessageFns<CrawlerState> = {
  encode(
    message: CrawlerState,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.status !== "") {
      writer.uint32(10).string(message.status);
    }
    if (message.bytesCollected !== 0) {
      writer.uint32(16).uint64(message.bytesCollected);
    }
    if (message.recordsCollected !== 0) {
      writer.uint32(24).uint64(message.recordsCollected);
    }
    for (const v of message.repos) {
      HfRepo.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CrawlerState {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerState();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.bytesCollected = longToNumber(reader.uint64());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.recordsCollected = longToNumber(reader.uint64());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.repos.push(HfRepo.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerState {
    return {
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      bytesCollected: isSet(object.bytesCollected)
        ? globalThis.Number(object.bytesCollected)
        : 0,
      recordsCollected: isSet(object.recordsCollected)
        ? globalThis.Number(object.recordsCollected)
        : 0,
      repos: globalThis.Array.isArray(object?.repos)
        ? object.repos.map((e: any) => HfRepo.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CrawlerState): unknown {
    const obj: any = {};
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.bytesCollected !== 0) {
      obj.bytesCollected = Math.round(message.bytesCollected);
    }
    if (message.recordsCollected !== 0) {
      obj.recordsCollected = Math.round(message.recordsCollected);
    }
    if (message.repos?.length) {
      obj.repos = message.repos.map(e => HfRepo.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerState>): CrawlerState {
    return CrawlerState.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerState>): CrawlerState {
    const message = createBaseCrawlerState();
    message.status = object.status ?? "";
    message.bytesCollected = object.bytesCollected ?? 0;
    message.recordsCollected = object.recordsCollected ?? 0;
    message.repos = object.repos?.map(e => HfRepo.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGravityTaskState(): GravityTaskState {
  return {
    gravityTaskId: "",
    name: "",
    status: "",
    startTime: undefined,
    crawlerIds: [],
    crawlerWorkflows: [],
  };
}

export const GravityTaskState: MessageFns<GravityTaskState> = {
  encode(
    message: GravityTaskState,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    if (message.status !== "") {
      writer.uint32(26).string(message.status);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.startTime),
        writer.uint32(34).fork(),
      ).join();
    }
    for (const v of message.crawlerIds) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.crawlerWorkflows) {
      Crawler.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GravityTaskState {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGravityTaskState();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.crawlerIds.push(reader.string());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.crawlerWorkflows.push(
            Crawler.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GravityTaskState {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      startTime: isSet(object.startTime)
        ? fromJsonTimestamp(object.startTime)
        : undefined,
      crawlerIds: globalThis.Array.isArray(object?.crawlerIds)
        ? object.crawlerIds.map((e: any) => globalThis.String(e))
        : [],
      crawlerWorkflows: globalThis.Array.isArray(object?.crawlerWorkflows)
        ? object.crawlerWorkflows.map((e: any) => Crawler.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GravityTaskState): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.crawlerIds?.length) {
      obj.crawlerIds = message.crawlerIds;
    }
    if (message.crawlerWorkflows?.length) {
      obj.crawlerWorkflows = message.crawlerWorkflows.map(e =>
        Crawler.toJSON(e),
      );
    }
    return obj;
  },

  create(base?: DeepPartial<GravityTaskState>): GravityTaskState {
    return GravityTaskState.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GravityTaskState>): GravityTaskState {
    const message = createBaseGravityTaskState();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.name = object.name ?? "";
    message.status = object.status ?? "";
    message.startTime = object.startTime ?? undefined;
    message.crawlerIds = object.crawlerIds?.map(e => e) || [];
    message.crawlerWorkflows =
      object.crawlerWorkflows?.map(e => Crawler.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGravityMarketplaceTaskState(): GravityMarketplaceTaskState {
  return {
    gravityTaskId: "",
    name: "",
    status: "",
    startTime: undefined,
    crawlerIds: [],
    crawlerWorkflows: [],
    taskRecordsCollected: 0,
    taskBytesCollected: 0,
    description: "",
    imageUrl: "",
    viewCount: 0,
    downloadCount: 0,
    tags: [],
  };
}

export const GravityMarketplaceTaskState: MessageFns<GravityMarketplaceTaskState> =
  {
    encode(
      message: GravityMarketplaceTaskState,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      if (message.name !== "") {
        writer.uint32(18).string(message.name);
      }
      if (message.status !== "") {
        writer.uint32(26).string(message.status);
      }
      if (message.startTime !== undefined) {
        Timestamp.encode(
          toTimestamp(message.startTime),
          writer.uint32(34).fork(),
        ).join();
      }
      for (const v of message.crawlerIds) {
        writer.uint32(42).string(v!);
      }
      for (const v of message.crawlerWorkflows) {
        Crawler.encode(v!, writer.uint32(50).fork()).join();
      }
      if (message.taskRecordsCollected !== 0) {
        writer.uint32(56).uint64(message.taskRecordsCollected);
      }
      if (message.taskBytesCollected !== 0) {
        writer.uint32(64).uint64(message.taskBytesCollected);
      }
      if (message.description !== "") {
        writer.uint32(74).string(message.description);
      }
      if (message.imageUrl !== "") {
        writer.uint32(82).string(message.imageUrl);
      }
      if (message.viewCount !== 0) {
        writer.uint32(88).uint64(message.viewCount);
      }
      if (message.downloadCount !== 0) {
        writer.uint32(96).uint64(message.downloadCount);
      }
      for (const v of message.tags) {
        writer.uint32(106).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GravityMarketplaceTaskState {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGravityMarketplaceTaskState();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.name = reader.string();
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.status = reader.string();
            continue;
          }
          case 4: {
            if (tag !== 34) {
              break;
            }

            message.startTime = fromTimestamp(
              Timestamp.decode(reader, reader.uint32()),
            );
            continue;
          }
          case 5: {
            if (tag !== 42) {
              break;
            }

            message.crawlerIds.push(reader.string());
            continue;
          }
          case 6: {
            if (tag !== 50) {
              break;
            }

            message.crawlerWorkflows.push(
              Crawler.decode(reader, reader.uint32()),
            );
            continue;
          }
          case 7: {
            if (tag !== 56) {
              break;
            }

            message.taskRecordsCollected = longToNumber(reader.uint64());
            continue;
          }
          case 8: {
            if (tag !== 64) {
              break;
            }

            message.taskBytesCollected = longToNumber(reader.uint64());
            continue;
          }
          case 9: {
            if (tag !== 74) {
              break;
            }

            message.description = reader.string();
            continue;
          }
          case 10: {
            if (tag !== 82) {
              break;
            }

            message.imageUrl = reader.string();
            continue;
          }
          case 11: {
            if (tag !== 88) {
              break;
            }

            message.viewCount = longToNumber(reader.uint64());
            continue;
          }
          case 12: {
            if (tag !== 96) {
              break;
            }

            message.downloadCount = longToNumber(reader.uint64());
            continue;
          }
          case 13: {
            if (tag !== 106) {
              break;
            }

            message.tags.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GravityMarketplaceTaskState {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
        name: isSet(object.name) ? globalThis.String(object.name) : "",
        status: isSet(object.status) ? globalThis.String(object.status) : "",
        startTime: isSet(object.startTime)
          ? fromJsonTimestamp(object.startTime)
          : undefined,
        crawlerIds: globalThis.Array.isArray(object?.crawlerIds)
          ? object.crawlerIds.map((e: any) => globalThis.String(e))
          : [],
        crawlerWorkflows: globalThis.Array.isArray(object?.crawlerWorkflows)
          ? object.crawlerWorkflows.map((e: any) => Crawler.fromJSON(e))
          : [],
        taskRecordsCollected: isSet(object.taskRecordsCollected)
          ? globalThis.Number(object.taskRecordsCollected)
          : 0,
        taskBytesCollected: isSet(object.taskBytesCollected)
          ? globalThis.Number(object.taskBytesCollected)
          : 0,
        description: isSet(object.description)
          ? globalThis.String(object.description)
          : "",
        imageUrl: isSet(object.imageUrl)
          ? globalThis.String(object.imageUrl)
          : "",
        viewCount: isSet(object.viewCount)
          ? globalThis.Number(object.viewCount)
          : 0,
        downloadCount: isSet(object.downloadCount)
          ? globalThis.Number(object.downloadCount)
          : 0,
        tags: globalThis.Array.isArray(object?.tags)
          ? object.tags.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: GravityMarketplaceTaskState): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      if (message.name !== "") {
        obj.name = message.name;
      }
      if (message.status !== "") {
        obj.status = message.status;
      }
      if (message.startTime !== undefined) {
        obj.startTime = message.startTime.toISOString();
      }
      if (message.crawlerIds?.length) {
        obj.crawlerIds = message.crawlerIds;
      }
      if (message.crawlerWorkflows?.length) {
        obj.crawlerWorkflows = message.crawlerWorkflows.map(e =>
          Crawler.toJSON(e),
        );
      }
      if (message.taskRecordsCollected !== 0) {
        obj.taskRecordsCollected = Math.round(message.taskRecordsCollected);
      }
      if (message.taskBytesCollected !== 0) {
        obj.taskBytesCollected = Math.round(message.taskBytesCollected);
      }
      if (message.description !== "") {
        obj.description = message.description;
      }
      if (message.imageUrl !== "") {
        obj.imageUrl = message.imageUrl;
      }
      if (message.viewCount !== 0) {
        obj.viewCount = Math.round(message.viewCount);
      }
      if (message.downloadCount !== 0) {
        obj.downloadCount = Math.round(message.downloadCount);
      }
      if (message.tags?.length) {
        obj.tags = message.tags;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GravityMarketplaceTaskState>,
    ): GravityMarketplaceTaskState {
      return GravityMarketplaceTaskState.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GravityMarketplaceTaskState>,
    ): GravityMarketplaceTaskState {
      const message = createBaseGravityMarketplaceTaskState();
      message.gravityTaskId = object.gravityTaskId ?? "";
      message.name = object.name ?? "";
      message.status = object.status ?? "";
      message.startTime = object.startTime ?? undefined;
      message.crawlerIds = object.crawlerIds?.map(e => e) || [];
      message.crawlerWorkflows =
        object.crawlerWorkflows?.map(e => Crawler.fromPartial(e)) || [];
      message.taskRecordsCollected = object.taskRecordsCollected ?? 0;
      message.taskBytesCollected = object.taskBytesCollected ?? 0;
      message.description = object.description ?? "";
      message.imageUrl = object.imageUrl ?? "";
      message.viewCount = object.viewCount ?? 0;
      message.downloadCount = object.downloadCount ?? 0;
      message.tags = object.tags?.map(e => e) || [];
      return message;
    },
  };

function createBaseGetGravityTasksRequest(): GetGravityTasksRequest {
  return { gravityTaskId: undefined, includeCrawlers: undefined };
}

export const GetGravityTasksRequest: MessageFns<GetGravityTasksRequest> = {
  encode(
    message: GetGravityTasksRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== undefined) {
      writer.uint32(10).string(message.gravityTaskId);
    }
    if (message.includeCrawlers !== undefined) {
      writer.uint32(16).bool(message.includeCrawlers);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetGravityTasksRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetGravityTasksRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.includeCrawlers = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetGravityTasksRequest {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : undefined,
      includeCrawlers: isSet(object.includeCrawlers)
        ? globalThis.Boolean(object.includeCrawlers)
        : undefined,
    };
  },

  toJSON(message: GetGravityTasksRequest): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== undefined) {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.includeCrawlers !== undefined) {
      obj.includeCrawlers = message.includeCrawlers;
    }
    return obj;
  },

  create(base?: DeepPartial<GetGravityTasksRequest>): GetGravityTasksRequest {
    return GetGravityTasksRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GetGravityTasksRequest>,
  ): GetGravityTasksRequest {
    const message = createBaseGetGravityTasksRequest();
    message.gravityTaskId = object.gravityTaskId ?? undefined;
    message.includeCrawlers = object.includeCrawlers ?? undefined;
    return message;
  },
};

function createBaseGetGravityTasksResponse(): GetGravityTasksResponse {
  return { gravityTaskStates: [] };
}

export const GetGravityTasksResponse: MessageFns<GetGravityTasksResponse> = {
  encode(
    message: GetGravityTasksResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.gravityTaskStates) {
      GravityTaskState.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetGravityTasksResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetGravityTasksResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskStates.push(
            GravityTaskState.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetGravityTasksResponse {
    return {
      gravityTaskStates: globalThis.Array.isArray(object?.gravityTaskStates)
        ? object.gravityTaskStates.map((e: any) => GravityTaskState.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GetGravityTasksResponse): unknown {
    const obj: any = {};
    if (message.gravityTaskStates?.length) {
      obj.gravityTaskStates = message.gravityTaskStates.map(e =>
        GravityTaskState.toJSON(e),
      );
    }
    return obj;
  },

  create(base?: DeepPartial<GetGravityTasksResponse>): GetGravityTasksResponse {
    return GetGravityTasksResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GetGravityTasksResponse>,
  ): GetGravityTasksResponse {
    const message = createBaseGetGravityTasksResponse();
    message.gravityTaskStates =
      object.gravityTaskStates?.map(e => GravityTaskState.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGravityTask(): GravityTask {
  return {
    topic: undefined,
    platform: "",
    keyword: undefined,
    postStartDatetime: undefined,
    postEndDatetime: undefined,
  };
}

export const GravityTask: MessageFns<GravityTask> = {
  encode(
    message: GravityTask,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.topic !== undefined) {
      writer.uint32(10).string(message.topic);
    }
    if (message.platform !== "") {
      writer.uint32(18).string(message.platform);
    }
    if (message.keyword !== undefined) {
      writer.uint32(26).string(message.keyword);
    }
    if (message.postStartDatetime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.postStartDatetime),
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.postEndDatetime !== undefined) {
      Timestamp.encode(
        toTimestamp(message.postEndDatetime),
        writer.uint32(42).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GravityTask {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGravityTask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.topic = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.platform = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.keyword = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.postStartDatetime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.postEndDatetime = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GravityTask {
    return {
      topic: isSet(object.topic) ? globalThis.String(object.topic) : undefined,
      platform: isSet(object.platform)
        ? globalThis.String(object.platform)
        : "",
      keyword: isSet(object.keyword)
        ? globalThis.String(object.keyword)
        : undefined,
      postStartDatetime: isSet(object.postStartDatetime)
        ? fromJsonTimestamp(object.postStartDatetime)
        : undefined,
      postEndDatetime: isSet(object.postEndDatetime)
        ? fromJsonTimestamp(object.postEndDatetime)
        : undefined,
    };
  },

  toJSON(message: GravityTask): unknown {
    const obj: any = {};
    if (message.topic !== undefined) {
      obj.topic = message.topic;
    }
    if (message.platform !== "") {
      obj.platform = message.platform;
    }
    if (message.keyword !== undefined) {
      obj.keyword = message.keyword;
    }
    if (message.postStartDatetime !== undefined) {
      obj.postStartDatetime = message.postStartDatetime.toISOString();
    }
    if (message.postEndDatetime !== undefined) {
      obj.postEndDatetime = message.postEndDatetime.toISOString();
    }
    return obj;
  },

  create(base?: DeepPartial<GravityTask>): GravityTask {
    return GravityTask.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GravityTask>): GravityTask {
    const message = createBaseGravityTask();
    message.topic = object.topic ?? undefined;
    message.platform = object.platform ?? "";
    message.keyword = object.keyword ?? undefined;
    message.postStartDatetime = object.postStartDatetime ?? undefined;
    message.postEndDatetime = object.postEndDatetime ?? undefined;
    return message;
  },
};

function createBaseNotificationRequest(): NotificationRequest {
  return { type: "", address: "", redirectUrl: undefined };
}

export const NotificationRequest: MessageFns<NotificationRequest> = {
  encode(
    message: NotificationRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (message.address !== "") {
      writer.uint32(18).string(message.address);
    }
    if (message.redirectUrl !== undefined) {
      writer.uint32(26).string(message.redirectUrl);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): NotificationRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNotificationRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.address = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.redirectUrl = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NotificationRequest {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      address: isSet(object.address) ? globalThis.String(object.address) : "",
      redirectUrl: isSet(object.redirectUrl)
        ? globalThis.String(object.redirectUrl)
        : undefined,
    };
  },

  toJSON(message: NotificationRequest): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.address !== "") {
      obj.address = message.address;
    }
    if (message.redirectUrl !== undefined) {
      obj.redirectUrl = message.redirectUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<NotificationRequest>): NotificationRequest {
    return NotificationRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<NotificationRequest>): NotificationRequest {
    const message = createBaseNotificationRequest();
    message.type = object.type ?? "";
    message.address = object.address ?? "";
    message.redirectUrl = object.redirectUrl ?? undefined;
    return message;
  },
};

function createBaseGetCrawlerRequest(): GetCrawlerRequest {
  return { crawlerId: "" };
}

export const GetCrawlerRequest: MessageFns<GetCrawlerRequest> = {
  encode(
    message: GetCrawlerRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetCrawlerRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetCrawlerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetCrawlerRequest {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
    };
  },

  toJSON(message: GetCrawlerRequest): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    return obj;
  },

  create(base?: DeepPartial<GetCrawlerRequest>): GetCrawlerRequest {
    return GetCrawlerRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetCrawlerRequest>): GetCrawlerRequest {
    const message = createBaseGetCrawlerRequest();
    message.crawlerId = object.crawlerId ?? "";
    return message;
  },
};

function createBaseGetMarketplaceCrawlersResponse(): GetMarketplaceCrawlersResponse {
  return { crawlerId: [] };
}

export const GetMarketplaceCrawlersResponse: MessageFns<GetMarketplaceCrawlersResponse> =
  {
    encode(
      message: GetMarketplaceCrawlersResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.crawlerId) {
        writer.uint32(10).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetMarketplaceCrawlersResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetMarketplaceCrawlersResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.crawlerId.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetMarketplaceCrawlersResponse {
      return {
        crawlerId: globalThis.Array.isArray(object?.crawlerId)
          ? object.crawlerId.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: GetMarketplaceCrawlersResponse): unknown {
      const obj: any = {};
      if (message.crawlerId?.length) {
        obj.crawlerId = message.crawlerId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetMarketplaceCrawlersResponse>,
    ): GetMarketplaceCrawlersResponse {
      return GetMarketplaceCrawlersResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetMarketplaceCrawlersResponse>,
    ): GetMarketplaceCrawlersResponse {
      const message = createBaseGetMarketplaceCrawlersResponse();
      message.crawlerId = object.crawlerId?.map(e => e) || [];
      return message;
    },
  };

function createBaseCompleteCrawlerRequest(): CompleteCrawlerRequest {
  return { crawlerId: "", status: "" };
}

export const CompleteCrawlerRequest: MessageFns<CompleteCrawlerRequest> = {
  encode(
    message: CompleteCrawlerRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    if (message.status !== "") {
      writer.uint32(26).string(message.status);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CompleteCrawlerRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCompleteCrawlerRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.status = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CompleteCrawlerRequest {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
      status: isSet(object.status) ? globalThis.String(object.status) : "",
    };
  },

  toJSON(message: CompleteCrawlerRequest): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    if (message.status !== "") {
      obj.status = message.status;
    }
    return obj;
  },

  create(base?: DeepPartial<CompleteCrawlerRequest>): CompleteCrawlerRequest {
    return CompleteCrawlerRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CompleteCrawlerRequest>,
  ): CompleteCrawlerRequest {
    const message = createBaseCompleteCrawlerRequest();
    message.crawlerId = object.crawlerId ?? "";
    message.status = object.status ?? "";
    return message;
  },
};

function createBaseGetCrawlerResponse(): GetCrawlerResponse {
  return { crawler: undefined };
}

export const GetCrawlerResponse: MessageFns<GetCrawlerResponse> = {
  encode(
    message: GetCrawlerResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawler !== undefined) {
      Crawler.encode(message.crawler, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetCrawlerResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetCrawlerResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawler = Crawler.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetCrawlerResponse {
    return {
      crawler: isSet(object.crawler)
        ? Crawler.fromJSON(object.crawler)
        : undefined,
    };
  },

  toJSON(message: GetCrawlerResponse): unknown {
    const obj: any = {};
    if (message.crawler !== undefined) {
      obj.crawler = Crawler.toJSON(message.crawler);
    }
    return obj;
  },

  create(base?: DeepPartial<GetCrawlerResponse>): GetCrawlerResponse {
    return GetCrawlerResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetCrawlerResponse>): GetCrawlerResponse {
    const message = createBaseGetCrawlerResponse();
    message.crawler =
      object.crawler !== undefined && object.crawler !== null
        ? Crawler.fromPartial(object.crawler)
        : undefined;
    return message;
  },
};

function createBaseCreateGravityTaskRequest(): CreateGravityTaskRequest {
  return {
    gravityTasks: [],
    name: "",
    notificationRequests: [],
    gravityTaskId: undefined,
  };
}

export const CreateGravityTaskRequest: MessageFns<CreateGravityTaskRequest> = {
  encode(
    message: CreateGravityTaskRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    for (const v of message.gravityTasks) {
      GravityTask.encode(v!, writer.uint32(10).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    for (const v of message.notificationRequests) {
      NotificationRequest.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.gravityTaskId !== undefined) {
      writer.uint32(34).string(message.gravityTaskId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CreateGravityTaskRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateGravityTaskRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTasks.push(
            GravityTask.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.notificationRequests.push(
            NotificationRequest.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CreateGravityTaskRequest {
    return {
      gravityTasks: globalThis.Array.isArray(object?.gravityTasks)
        ? object.gravityTasks.map((e: any) => GravityTask.fromJSON(e))
        : [],
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      notificationRequests: globalThis.Array.isArray(
        object?.notificationRequests,
      )
        ? object.notificationRequests.map((e: any) =>
            NotificationRequest.fromJSON(e),
          )
        : [],
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : undefined,
    };
  },

  toJSON(message: CreateGravityTaskRequest): unknown {
    const obj: any = {};
    if (message.gravityTasks?.length) {
      obj.gravityTasks = message.gravityTasks.map(e => GravityTask.toJSON(e));
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.notificationRequests?.length) {
      obj.notificationRequests = message.notificationRequests.map(e =>
        NotificationRequest.toJSON(e),
      );
    }
    if (message.gravityTaskId !== undefined) {
      obj.gravityTaskId = message.gravityTaskId;
    }
    return obj;
  },

  create(
    base?: DeepPartial<CreateGravityTaskRequest>,
  ): CreateGravityTaskRequest {
    return CreateGravityTaskRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CreateGravityTaskRequest>,
  ): CreateGravityTaskRequest {
    const message = createBaseCreateGravityTaskRequest();
    message.gravityTasks =
      object.gravityTasks?.map(e => GravityTask.fromPartial(e)) || [];
    message.name = object.name ?? "";
    message.notificationRequests =
      object.notificationRequests?.map(e =>
        NotificationRequest.fromPartial(e),
      ) || [];
    message.gravityTaskId = object.gravityTaskId ?? undefined;
    return message;
  },
};

function createBaseCreateGravityTaskResponse(): CreateGravityTaskResponse {
  return { gravityTaskId: "" };
}

export const CreateGravityTaskResponse: MessageFns<CreateGravityTaskResponse> =
  {
    encode(
      message: CreateGravityTaskResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): CreateGravityTaskResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseCreateGravityTaskResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): CreateGravityTaskResponse {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
      };
    },

    toJSON(message: CreateGravityTaskResponse): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<CreateGravityTaskResponse>,
    ): CreateGravityTaskResponse {
      return CreateGravityTaskResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<CreateGravityTaskResponse>,
    ): CreateGravityTaskResponse {
      const message = createBaseCreateGravityTaskResponse();
      message.gravityTaskId = object.gravityTaskId ?? "";
      return message;
    },
  };

function createBaseBuildDatasetRequest(): BuildDatasetRequest {
  return {
    crawlerId: "",
    notificationRequests: [],
    maxRows: 0,
    isMarketplace: undefined,
  };
}

export const BuildDatasetRequest: MessageFns<BuildDatasetRequest> = {
  encode(
    message: BuildDatasetRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    for (const v of message.notificationRequests) {
      NotificationRequest.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.maxRows !== 0) {
      writer.uint32(24).int64(message.maxRows);
    }
    if (message.isMarketplace !== undefined) {
      writer.uint32(32).bool(message.isMarketplace);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BuildDatasetRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.notificationRequests.push(
            NotificationRequest.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.maxRows = longToNumber(reader.int64());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.isMarketplace = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildDatasetRequest {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
      notificationRequests: globalThis.Array.isArray(
        object?.notificationRequests,
      )
        ? object.notificationRequests.map((e: any) =>
            NotificationRequest.fromJSON(e),
          )
        : [],
      maxRows: isSet(object.maxRows) ? globalThis.Number(object.maxRows) : 0,
      isMarketplace: isSet(object.isMarketplace)
        ? globalThis.Boolean(object.isMarketplace)
        : undefined,
    };
  },

  toJSON(message: BuildDatasetRequest): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    if (message.notificationRequests?.length) {
      obj.notificationRequests = message.notificationRequests.map(e =>
        NotificationRequest.toJSON(e),
      );
    }
    if (message.maxRows !== 0) {
      obj.maxRows = Math.round(message.maxRows);
    }
    if (message.isMarketplace !== undefined) {
      obj.isMarketplace = message.isMarketplace;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildDatasetRequest>): BuildDatasetRequest {
    return BuildDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildDatasetRequest>): BuildDatasetRequest {
    const message = createBaseBuildDatasetRequest();
    message.crawlerId = object.crawlerId ?? "";
    message.notificationRequests =
      object.notificationRequests?.map(e =>
        NotificationRequest.fromPartial(e),
      ) || [];
    message.maxRows = object.maxRows ?? 0;
    message.isMarketplace = object.isMarketplace ?? undefined;
    return message;
  },
};

function createBaseBuildDatasetResponse(): BuildDatasetResponse {
  return { datasetId: "", dataset: undefined };
}

export const BuildDatasetResponse: MessageFns<BuildDatasetResponse> = {
  encode(
    message: BuildDatasetResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    if (message.dataset !== undefined) {
      Dataset.encode(message.dataset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BuildDatasetResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildDatasetResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dataset = Dataset.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildDatasetResponse {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
      dataset: isSet(object.dataset)
        ? Dataset.fromJSON(object.dataset)
        : undefined,
    };
  },

  toJSON(message: BuildDatasetResponse): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.dataset !== undefined) {
      obj.dataset = Dataset.toJSON(message.dataset);
    }
    return obj;
  },

  create(base?: DeepPartial<BuildDatasetResponse>): BuildDatasetResponse {
    return BuildDatasetResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BuildDatasetResponse>): BuildDatasetResponse {
    const message = createBaseBuildDatasetResponse();
    message.datasetId = object.datasetId ?? "";
    message.dataset =
      object.dataset !== undefined && object.dataset !== null
        ? Dataset.fromPartial(object.dataset)
        : undefined;
    return message;
  },
};

function createBaseBuildAllDatasetsRequest(): BuildAllDatasetsRequest {
  return {
    gravityTaskId: "",
    buildCrawlersConfig: [],
    isMarketplace: undefined,
  };
}

export const BuildAllDatasetsRequest: MessageFns<BuildAllDatasetsRequest> = {
  encode(
    message: BuildAllDatasetsRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    for (const v of message.buildCrawlersConfig) {
      BuildDatasetRequest.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.isMarketplace !== undefined) {
      writer.uint32(24).bool(message.isMarketplace);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BuildAllDatasetsRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildAllDatasetsRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.buildCrawlersConfig.push(
            BuildDatasetRequest.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.isMarketplace = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildAllDatasetsRequest {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      buildCrawlersConfig: globalThis.Array.isArray(object?.buildCrawlersConfig)
        ? object.buildCrawlersConfig.map((e: any) =>
            BuildDatasetRequest.fromJSON(e),
          )
        : [],
      isMarketplace: isSet(object.isMarketplace)
        ? globalThis.Boolean(object.isMarketplace)
        : undefined,
    };
  },

  toJSON(message: BuildAllDatasetsRequest): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.buildCrawlersConfig?.length) {
      obj.buildCrawlersConfig = message.buildCrawlersConfig.map(e =>
        BuildDatasetRequest.toJSON(e),
      );
    }
    if (message.isMarketplace !== undefined) {
      obj.isMarketplace = message.isMarketplace;
    }
    return obj;
  },

  create(base?: DeepPartial<BuildAllDatasetsRequest>): BuildAllDatasetsRequest {
    return BuildAllDatasetsRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BuildAllDatasetsRequest>,
  ): BuildAllDatasetsRequest {
    const message = createBaseBuildAllDatasetsRequest();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.buildCrawlersConfig =
      object.buildCrawlersConfig?.map(e =>
        BuildDatasetRequest.fromPartial(e),
      ) || [];
    message.isMarketplace = object.isMarketplace ?? undefined;
    return message;
  },
};

function createBaseBuildAllDatasetsResponse(): BuildAllDatasetsResponse {
  return { gravityTaskId: "", datasets: [] };
}

export const BuildAllDatasetsResponse: MessageFns<BuildAllDatasetsResponse> = {
  encode(
    message: BuildAllDatasetsResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    for (const v of message.datasets) {
      Dataset.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): BuildAllDatasetsResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildAllDatasetsResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.datasets.push(Dataset.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildAllDatasetsResponse {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
      datasets: globalThis.Array.isArray(object?.datasets)
        ? object.datasets.map((e: any) => Dataset.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BuildAllDatasetsResponse): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    if (message.datasets?.length) {
      obj.datasets = message.datasets.map(e => Dataset.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<BuildAllDatasetsResponse>,
  ): BuildAllDatasetsResponse {
    return BuildAllDatasetsResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<BuildAllDatasetsResponse>,
  ): BuildAllDatasetsResponse {
    const message = createBaseBuildAllDatasetsResponse();
    message.gravityTaskId = object.gravityTaskId ?? "";
    message.datasets = object.datasets?.map(e => Dataset.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAddPersistentGravityTaskRequest(): AddPersistentGravityTaskRequest {
  return { gravityTaskId: "" };
}

export const AddPersistentGravityTaskRequest: MessageFns<AddPersistentGravityTaskRequest> =
  {
    encode(
      message: AddPersistentGravityTaskRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): AddPersistentGravityTaskRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseAddPersistentGravityTaskRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): AddPersistentGravityTaskRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
      };
    },

    toJSON(message: AddPersistentGravityTaskRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<AddPersistentGravityTaskRequest>,
    ): AddPersistentGravityTaskRequest {
      return AddPersistentGravityTaskRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<AddPersistentGravityTaskRequest>,
    ): AddPersistentGravityTaskRequest {
      const message = createBaseAddPersistentGravityTaskRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      return message;
    },
  };

function createBaseNebula(): Nebula {
  return { error: "", fileSizeBytes: 0, url: "" };
}

export const Nebula: MessageFns<Nebula> = {
  encode(
    message: Nebula,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.error !== "") {
      writer.uint32(10).string(message.error);
    }
    if (message.fileSizeBytes !== 0) {
      writer.uint32(16).int64(message.fileSizeBytes);
    }
    if (message.url !== "") {
      writer.uint32(26).string(message.url);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Nebula {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNebula();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.error = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.fileSizeBytes = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.url = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Nebula {
    return {
      error: isSet(object.error) ? globalThis.String(object.error) : "",
      fileSizeBytes: isSet(object.fileSizeBytes)
        ? globalThis.Number(object.fileSizeBytes)
        : 0,
      url: isSet(object.url) ? globalThis.String(object.url) : "",
    };
  },

  toJSON(message: Nebula): unknown {
    const obj: any = {};
    if (message.error !== "") {
      obj.error = message.error;
    }
    if (message.fileSizeBytes !== 0) {
      obj.fileSizeBytes = Math.round(message.fileSizeBytes);
    }
    if (message.url !== "") {
      obj.url = message.url;
    }
    return obj;
  },

  create(base?: DeepPartial<Nebula>): Nebula {
    return Nebula.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Nebula>): Nebula {
    const message = createBaseNebula();
    message.error = object.error ?? "";
    message.fileSizeBytes = object.fileSizeBytes ?? 0;
    message.url = object.url ?? "";
    return message;
  },
};

function createBaseDataset(): Dataset {
  return {
    crawlerWorkflowId: "",
    createDate: undefined,
    expireDate: undefined,
    files: [],
    status: "",
    statusMessage: "",
    steps: [],
    totalSteps: 0,
    nebula: undefined,
  };
}

export const Dataset: MessageFns<Dataset> = {
  encode(
    message: Dataset,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerWorkflowId !== "") {
      writer.uint32(10).string(message.crawlerWorkflowId);
    }
    if (message.createDate !== undefined) {
      Timestamp.encode(
        toTimestamp(message.createDate),
        writer.uint32(18).fork(),
      ).join();
    }
    if (message.expireDate !== undefined) {
      Timestamp.encode(
        toTimestamp(message.expireDate),
        writer.uint32(26).fork(),
      ).join();
    }
    for (const v of message.files) {
      DatasetFile.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.status !== "") {
      writer.uint32(42).string(message.status);
    }
    if (message.statusMessage !== "") {
      writer.uint32(50).string(message.statusMessage);
    }
    for (const v of message.steps) {
      DatasetStep.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.totalSteps !== 0) {
      writer.uint32(64).int64(message.totalSteps);
    }
    if (message.nebula !== undefined) {
      Nebula.encode(message.nebula, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Dataset {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerWorkflowId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createDate = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.expireDate = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.files.push(DatasetFile.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.status = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.statusMessage = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.steps.push(DatasetStep.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.totalSteps = longToNumber(reader.int64());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.nebula = Nebula.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Dataset {
    return {
      crawlerWorkflowId: isSet(object.crawlerWorkflowId)
        ? globalThis.String(object.crawlerWorkflowId)
        : "",
      createDate: isSet(object.createDate)
        ? fromJsonTimestamp(object.createDate)
        : undefined,
      expireDate: isSet(object.expireDate)
        ? fromJsonTimestamp(object.expireDate)
        : undefined,
      files: globalThis.Array.isArray(object?.files)
        ? object.files.map((e: any) => DatasetFile.fromJSON(e))
        : [],
      status: isSet(object.status) ? globalThis.String(object.status) : "",
      statusMessage: isSet(object.statusMessage)
        ? globalThis.String(object.statusMessage)
        : "",
      steps: globalThis.Array.isArray(object?.steps)
        ? object.steps.map((e: any) => DatasetStep.fromJSON(e))
        : [],
      totalSteps: isSet(object.totalSteps)
        ? globalThis.Number(object.totalSteps)
        : 0,
      nebula: isSet(object.nebula) ? Nebula.fromJSON(object.nebula) : undefined,
    };
  },

  toJSON(message: Dataset): unknown {
    const obj: any = {};
    if (message.crawlerWorkflowId !== "") {
      obj.crawlerWorkflowId = message.crawlerWorkflowId;
    }
    if (message.createDate !== undefined) {
      obj.createDate = message.createDate.toISOString();
    }
    if (message.expireDate !== undefined) {
      obj.expireDate = message.expireDate.toISOString();
    }
    if (message.files?.length) {
      obj.files = message.files.map(e => DatasetFile.toJSON(e));
    }
    if (message.status !== "") {
      obj.status = message.status;
    }
    if (message.statusMessage !== "") {
      obj.statusMessage = message.statusMessage;
    }
    if (message.steps?.length) {
      obj.steps = message.steps.map(e => DatasetStep.toJSON(e));
    }
    if (message.totalSteps !== 0) {
      obj.totalSteps = Math.round(message.totalSteps);
    }
    if (message.nebula !== undefined) {
      obj.nebula = Nebula.toJSON(message.nebula);
    }
    return obj;
  },

  create(base?: DeepPartial<Dataset>): Dataset {
    return Dataset.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<Dataset>): Dataset {
    const message = createBaseDataset();
    message.crawlerWorkflowId = object.crawlerWorkflowId ?? "";
    message.createDate = object.createDate ?? undefined;
    message.expireDate = object.expireDate ?? undefined;
    message.files = object.files?.map(e => DatasetFile.fromPartial(e)) || [];
    message.status = object.status ?? "";
    message.statusMessage = object.statusMessage ?? "";
    message.steps = object.steps?.map(e => DatasetStep.fromPartial(e)) || [];
    message.totalSteps = object.totalSteps ?? 0;
    message.nebula =
      object.nebula !== undefined && object.nebula !== null
        ? Nebula.fromPartial(object.nebula)
        : undefined;
    return message;
  },
};

function createBaseUpsertDatasetRequest(): UpsertDatasetRequest {
  return { datasetId: "", dataset: undefined };
}

export const UpsertDatasetRequest: MessageFns<UpsertDatasetRequest> = {
  encode(
    message: UpsertDatasetRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    if (message.dataset !== undefined) {
      Dataset.encode(message.dataset, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpsertDatasetRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dataset = Dataset.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertDatasetRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
      dataset: isSet(object.dataset)
        ? Dataset.fromJSON(object.dataset)
        : undefined,
    };
  },

  toJSON(message: UpsertDatasetRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.dataset !== undefined) {
      obj.dataset = Dataset.toJSON(message.dataset);
    }
    return obj;
  },

  create(base?: DeepPartial<UpsertDatasetRequest>): UpsertDatasetRequest {
    return UpsertDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpsertDatasetRequest>): UpsertDatasetRequest {
    const message = createBaseUpsertDatasetRequest();
    message.datasetId = object.datasetId ?? "";
    message.dataset =
      object.dataset !== undefined && object.dataset !== null
        ? Dataset.fromPartial(object.dataset)
        : undefined;
    return message;
  },
};

function createBaseUpsertNebulaRequest(): UpsertNebulaRequest {
  return { datasetId: "", nebulaId: "", nebula: undefined };
}

export const UpsertNebulaRequest: MessageFns<UpsertNebulaRequest> = {
  encode(
    message: UpsertNebulaRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    if (message.nebulaId !== "") {
      writer.uint32(18).string(message.nebulaId);
    }
    if (message.nebula !== undefined) {
      Nebula.encode(message.nebula, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): UpsertNebulaRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpsertNebulaRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nebulaId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.nebula = Nebula.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpsertNebulaRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
      nebulaId: isSet(object.nebulaId)
        ? globalThis.String(object.nebulaId)
        : "",
      nebula: isSet(object.nebula) ? Nebula.fromJSON(object.nebula) : undefined,
    };
  },

  toJSON(message: UpsertNebulaRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.nebulaId !== "") {
      obj.nebulaId = message.nebulaId;
    }
    if (message.nebula !== undefined) {
      obj.nebula = Nebula.toJSON(message.nebula);
    }
    return obj;
  },

  create(base?: DeepPartial<UpsertNebulaRequest>): UpsertNebulaRequest {
    return UpsertNebulaRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<UpsertNebulaRequest>): UpsertNebulaRequest {
    const message = createBaseUpsertNebulaRequest();
    message.datasetId = object.datasetId ?? "";
    message.nebulaId = object.nebulaId ?? "";
    message.nebula =
      object.nebula !== undefined && object.nebula !== null
        ? Nebula.fromPartial(object.nebula)
        : undefined;
    return message;
  },
};

function createBaseInsertDatasetFileRequest(): InsertDatasetFileRequest {
  return { datasetId: "", files: [] };
}

export const InsertDatasetFileRequest: MessageFns<InsertDatasetFileRequest> = {
  encode(
    message: InsertDatasetFileRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    for (const v of message.files) {
      DatasetFile.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): InsertDatasetFileRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInsertDatasetFileRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.files.push(DatasetFile.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): InsertDatasetFileRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
      files: globalThis.Array.isArray(object?.files)
        ? object.files.map((e: any) => DatasetFile.fromJSON(e))
        : [],
    };
  },

  toJSON(message: InsertDatasetFileRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.files?.length) {
      obj.files = message.files.map(e => DatasetFile.toJSON(e));
    }
    return obj;
  },

  create(
    base?: DeepPartial<InsertDatasetFileRequest>,
  ): InsertDatasetFileRequest {
    return InsertDatasetFileRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<InsertDatasetFileRequest>,
  ): InsertDatasetFileRequest {
    const message = createBaseInsertDatasetFileRequest();
    message.datasetId = object.datasetId ?? "";
    message.files = object.files?.map(e => DatasetFile.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDatasetFile(): DatasetFile {
  return {
    fileName: "",
    fileSizeBytes: 0,
    lastModified: undefined,
    numRows: 0,
    s3Key: "",
    url: "",
  };
}

export const DatasetFile: MessageFns<DatasetFile> = {
  encode(
    message: DatasetFile,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.fileName !== "") {
      writer.uint32(10).string(message.fileName);
    }
    if (message.fileSizeBytes !== 0) {
      writer.uint32(16).uint64(message.fileSizeBytes);
    }
    if (message.lastModified !== undefined) {
      Timestamp.encode(
        toTimestamp(message.lastModified),
        writer.uint32(26).fork(),
      ).join();
    }
    if (message.numRows !== 0) {
      writer.uint32(32).uint64(message.numRows);
    }
    if (message.s3Key !== "") {
      writer.uint32(42).string(message.s3Key);
    }
    if (message.url !== "") {
      writer.uint32(50).string(message.url);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetFile {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetFile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.fileName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.fileSizeBytes = longToNumber(reader.uint64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.lastModified = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.numRows = longToNumber(reader.uint64());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.s3Key = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.url = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetFile {
    return {
      fileName: isSet(object.fileName)
        ? globalThis.String(object.fileName)
        : "",
      fileSizeBytes: isSet(object.fileSizeBytes)
        ? globalThis.Number(object.fileSizeBytes)
        : 0,
      lastModified: isSet(object.lastModified)
        ? fromJsonTimestamp(object.lastModified)
        : undefined,
      numRows: isSet(object.numRows) ? globalThis.Number(object.numRows) : 0,
      s3Key: isSet(object.s3Key) ? globalThis.String(object.s3Key) : "",
      url: isSet(object.url) ? globalThis.String(object.url) : "",
    };
  },

  toJSON(message: DatasetFile): unknown {
    const obj: any = {};
    if (message.fileName !== "") {
      obj.fileName = message.fileName;
    }
    if (message.fileSizeBytes !== 0) {
      obj.fileSizeBytes = Math.round(message.fileSizeBytes);
    }
    if (message.lastModified !== undefined) {
      obj.lastModified = message.lastModified.toISOString();
    }
    if (message.numRows !== 0) {
      obj.numRows = Math.round(message.numRows);
    }
    if (message.s3Key !== "") {
      obj.s3Key = message.s3Key;
    }
    if (message.url !== "") {
      obj.url = message.url;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetFile>): DatasetFile {
    return DatasetFile.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetFile>): DatasetFile {
    const message = createBaseDatasetFile();
    message.fileName = object.fileName ?? "";
    message.fileSizeBytes = object.fileSizeBytes ?? 0;
    message.lastModified = object.lastModified ?? undefined;
    message.numRows = object.numRows ?? 0;
    message.s3Key = object.s3Key ?? "";
    message.url = object.url ?? "";
    return message;
  },
};

function createBaseDatasetStep(): DatasetStep {
  return { progress: 0, step: 0, stepName: "" };
}

export const DatasetStep: MessageFns<DatasetStep> = {
  encode(
    message: DatasetStep,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.progress !== 0) {
      writer.uint32(9).double(message.progress);
    }
    if (message.step !== 0) {
      writer.uint32(16).int64(message.step);
    }
    if (message.stepName !== "") {
      writer.uint32(26).string(message.stepName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetStep {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 9) {
            break;
          }

          message.progress = reader.double();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.step = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.stepName = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetStep {
    return {
      progress: isSet(object.progress) ? globalThis.Number(object.progress) : 0,
      step: isSet(object.step) ? globalThis.Number(object.step) : 0,
      stepName: isSet(object.stepName)
        ? globalThis.String(object.stepName)
        : "",
    };
  },

  toJSON(message: DatasetStep): unknown {
    const obj: any = {};
    if (message.progress !== 0) {
      obj.progress = message.progress;
    }
    if (message.step !== 0) {
      obj.step = Math.round(message.step);
    }
    if (message.stepName !== "") {
      obj.stepName = message.stepName;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetStep>): DatasetStep {
    return DatasetStep.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetStep>): DatasetStep {
    const message = createBaseDatasetStep();
    message.progress = object.progress ?? 0;
    message.step = object.step ?? 0;
    message.stepName = object.stepName ?? "";
    return message;
  },
};

function createBaseGetDatasetRequest(): GetDatasetRequest {
  return { datasetId: "" };
}

export const GetDatasetRequest: MessageFns<GetDatasetRequest> = {
  encode(
    message: GetDatasetRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GetDatasetRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
    };
  },

  toJSON(message: GetDatasetRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatasetRequest>): GetDatasetRequest {
    return GetDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatasetRequest>): GetDatasetRequest {
    const message = createBaseGetDatasetRequest();
    message.datasetId = object.datasetId ?? "";
    return message;
  },
};

function createBaseGetDatasetResponse(): GetDatasetResponse {
  return { dataset: undefined };
}

export const GetDatasetResponse: MessageFns<GetDatasetResponse> = {
  encode(
    message: GetDatasetResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.dataset !== undefined) {
      Dataset.encode(message.dataset, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetDatasetResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetDatasetResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.dataset = Dataset.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetDatasetResponse {
    return {
      dataset: isSet(object.dataset)
        ? Dataset.fromJSON(object.dataset)
        : undefined,
    };
  },

  toJSON(message: GetDatasetResponse): unknown {
    const obj: any = {};
    if (message.dataset !== undefined) {
      obj.dataset = Dataset.toJSON(message.dataset);
    }
    return obj;
  },

  create(base?: DeepPartial<GetDatasetResponse>): GetDatasetResponse {
    return GetDatasetResponse.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GetDatasetResponse>): GetDatasetResponse {
    const message = createBaseGetDatasetResponse();
    message.dataset =
      object.dataset !== undefined && object.dataset !== null
        ? Dataset.fromPartial(object.dataset)
        : undefined;
    return message;
  },
};

function createBaseCancelGravityTaskRequest(): CancelGravityTaskRequest {
  return { gravityTaskId: "" };
}

export const CancelGravityTaskRequest: MessageFns<CancelGravityTaskRequest> = {
  encode(
    message: CancelGravityTaskRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CancelGravityTaskRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelGravityTaskRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelGravityTaskRequest {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
    };
  },

  toJSON(message: CancelGravityTaskRequest): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    return obj;
  },

  create(
    base?: DeepPartial<CancelGravityTaskRequest>,
  ): CancelGravityTaskRequest {
    return CancelGravityTaskRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CancelGravityTaskRequest>,
  ): CancelGravityTaskRequest {
    const message = createBaseCancelGravityTaskRequest();
    message.gravityTaskId = object.gravityTaskId ?? "";
    return message;
  },
};

function createBaseCancelGravityTaskResponse(): CancelGravityTaskResponse {
  return { message: "" };
}

export const CancelGravityTaskResponse: MessageFns<CancelGravityTaskResponse> =
  {
    encode(
      message: CancelGravityTaskResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.message !== "") {
        writer.uint32(10).string(message.message);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): CancelGravityTaskResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseCancelGravityTaskResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.message = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): CancelGravityTaskResponse {
      return {
        message: isSet(object.message) ? globalThis.String(object.message) : "",
      };
    },

    toJSON(message: CancelGravityTaskResponse): unknown {
      const obj: any = {};
      if (message.message !== "") {
        obj.message = message.message;
      }
      return obj;
    },

    create(
      base?: DeepPartial<CancelGravityTaskResponse>,
    ): CancelGravityTaskResponse {
      return CancelGravityTaskResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<CancelGravityTaskResponse>,
    ): CancelGravityTaskResponse {
      const message = createBaseCancelGravityTaskResponse();
      message.message = object.message ?? "";
      return message;
    },
  };

function createBaseCancelDatasetRequest(): CancelDatasetRequest {
  return { datasetId: "" };
}

export const CancelDatasetRequest: MessageFns<CancelDatasetRequest> = {
  encode(
    message: CancelDatasetRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CancelDatasetRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelDatasetRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelDatasetRequest {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
    };
  },

  toJSON(message: CancelDatasetRequest): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelDatasetRequest>): CancelDatasetRequest {
    return CancelDatasetRequest.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CancelDatasetRequest>): CancelDatasetRequest {
    const message = createBaseCancelDatasetRequest();
    message.datasetId = object.datasetId ?? "";
    return message;
  },
};

function createBaseCancelDatasetResponse(): CancelDatasetResponse {
  return { message: "" };
}

export const CancelDatasetResponse: MessageFns<CancelDatasetResponse> = {
  encode(
    message: CancelDatasetResponse,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CancelDatasetResponse {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCancelDatasetResponse();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CancelDatasetResponse {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: CancelDatasetResponse): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create(base?: DeepPartial<CancelDatasetResponse>): CancelDatasetResponse {
    return CancelDatasetResponse.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<CancelDatasetResponse>,
  ): CancelDatasetResponse {
    const message = createBaseCancelDatasetResponse();
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseDatasetBillingCorrectionRequest(): DatasetBillingCorrectionRequest {
  return { requestedRowCount: 0, actualRowCount: 0 };
}

export const DatasetBillingCorrectionRequest: MessageFns<DatasetBillingCorrectionRequest> =
  {
    encode(
      message: DatasetBillingCorrectionRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.requestedRowCount !== 0) {
        writer.uint32(8).int64(message.requestedRowCount);
      }
      if (message.actualRowCount !== 0) {
        writer.uint32(16).int64(message.actualRowCount);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): DatasetBillingCorrectionRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseDatasetBillingCorrectionRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 8) {
              break;
            }

            message.requestedRowCount = longToNumber(reader.int64());
            continue;
          }
          case 2: {
            if (tag !== 16) {
              break;
            }

            message.actualRowCount = longToNumber(reader.int64());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): DatasetBillingCorrectionRequest {
      return {
        requestedRowCount: isSet(object.requestedRowCount)
          ? globalThis.Number(object.requestedRowCount)
          : 0,
        actualRowCount: isSet(object.actualRowCount)
          ? globalThis.Number(object.actualRowCount)
          : 0,
      };
    },

    toJSON(message: DatasetBillingCorrectionRequest): unknown {
      const obj: any = {};
      if (message.requestedRowCount !== 0) {
        obj.requestedRowCount = Math.round(message.requestedRowCount);
      }
      if (message.actualRowCount !== 0) {
        obj.actualRowCount = Math.round(message.actualRowCount);
      }
      return obj;
    },

    create(
      base?: DeepPartial<DatasetBillingCorrectionRequest>,
    ): DatasetBillingCorrectionRequest {
      return DatasetBillingCorrectionRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<DatasetBillingCorrectionRequest>,
    ): DatasetBillingCorrectionRequest {
      const message = createBaseDatasetBillingCorrectionRequest();
      message.requestedRowCount = object.requestedRowCount ?? 0;
      message.actualRowCount = object.actualRowCount ?? 0;
      return message;
    },
  };

function createBaseDatasetBillingCorrectionResponse(): DatasetBillingCorrectionResponse {
  return { refundAmount: 0 };
}

export const DatasetBillingCorrectionResponse: MessageFns<DatasetBillingCorrectionResponse> =
  {
    encode(
      message: DatasetBillingCorrectionResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.refundAmount !== 0) {
        writer.uint32(9).double(message.refundAmount);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): DatasetBillingCorrectionResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseDatasetBillingCorrectionResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 9) {
              break;
            }

            message.refundAmount = reader.double();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): DatasetBillingCorrectionResponse {
      return {
        refundAmount: isSet(object.refundAmount)
          ? globalThis.Number(object.refundAmount)
          : 0,
      };
    },

    toJSON(message: DatasetBillingCorrectionResponse): unknown {
      const obj: any = {};
      if (message.refundAmount !== 0) {
        obj.refundAmount = message.refundAmount;
      }
      return obj;
    },

    create(
      base?: DeepPartial<DatasetBillingCorrectionResponse>,
    ): DatasetBillingCorrectionResponse {
      return DatasetBillingCorrectionResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<DatasetBillingCorrectionResponse>,
    ): DatasetBillingCorrectionResponse {
      const message = createBaseDatasetBillingCorrectionResponse();
      message.refundAmount = object.refundAmount ?? 0;
      return message;
    },
  };

function createBaseGetMarketplaceDatasetsResponse(): GetMarketplaceDatasetsResponse {
  return { datasets: [] };
}

export const GetMarketplaceDatasetsResponse: MessageFns<GetMarketplaceDatasetsResponse> =
  {
    encode(
      message: GetMarketplaceDatasetsResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.datasets) {
        GravityMarketplaceTaskState.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetMarketplaceDatasetsResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetMarketplaceDatasetsResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.datasets.push(
              GravityMarketplaceTaskState.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetMarketplaceDatasetsResponse {
      return {
        datasets: globalThis.Array.isArray(object?.datasets)
          ? object.datasets.map((e: any) =>
              GravityMarketplaceTaskState.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetMarketplaceDatasetsResponse): unknown {
      const obj: any = {};
      if (message.datasets?.length) {
        obj.datasets = message.datasets.map(e =>
          GravityMarketplaceTaskState.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetMarketplaceDatasetsResponse>,
    ): GetMarketplaceDatasetsResponse {
      return GetMarketplaceDatasetsResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetMarketplaceDatasetsResponse>,
    ): GetMarketplaceDatasetsResponse {
      const message = createBaseGetMarketplaceDatasetsResponse();
      message.datasets =
        object.datasets?.map(e => GravityMarketplaceTaskState.fromPartial(e)) ||
        [];
      return message;
    },
  };

function createBaseGetGravityTaskDatasetFilesRequest(): GetGravityTaskDatasetFilesRequest {
  return { gravityTaskId: "" };
}

export const GetGravityTaskDatasetFilesRequest: MessageFns<GetGravityTaskDatasetFilesRequest> =
  {
    encode(
      message: GetGravityTaskDatasetFilesRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetGravityTaskDatasetFilesRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetGravityTaskDatasetFilesRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetGravityTaskDatasetFilesRequest {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
      };
    },

    toJSON(message: GetGravityTaskDatasetFilesRequest): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetGravityTaskDatasetFilesRequest>,
    ): GetGravityTaskDatasetFilesRequest {
      return GetGravityTaskDatasetFilesRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetGravityTaskDatasetFilesRequest>,
    ): GetGravityTaskDatasetFilesRequest {
      const message = createBaseGetGravityTaskDatasetFilesRequest();
      message.gravityTaskId = object.gravityTaskId ?? "";
      return message;
    },
  };

function createBaseCrawlerDatasetFiles(): CrawlerDatasetFiles {
  return { crawlerId: "", datasetFiles: [] };
}

export const CrawlerDatasetFiles: MessageFns<CrawlerDatasetFiles> = {
  encode(
    message: CrawlerDatasetFiles,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    for (const v of message.datasetFiles) {
      DatasetFileWithId.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CrawlerDatasetFiles {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerDatasetFiles();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.datasetFiles.push(
            DatasetFileWithId.decode(reader, reader.uint32()),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerDatasetFiles {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
      datasetFiles: globalThis.Array.isArray(object?.datasetFiles)
        ? object.datasetFiles.map((e: any) => DatasetFileWithId.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CrawlerDatasetFiles): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    if (message.datasetFiles?.length) {
      obj.datasetFiles = message.datasetFiles.map(e =>
        DatasetFileWithId.toJSON(e),
      );
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerDatasetFiles>): CrawlerDatasetFiles {
    return CrawlerDatasetFiles.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerDatasetFiles>): CrawlerDatasetFiles {
    const message = createBaseCrawlerDatasetFiles();
    message.crawlerId = object.crawlerId ?? "";
    message.datasetFiles =
      object.datasetFiles?.map(e => DatasetFileWithId.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCrawlerRawMinerFilesResponse(): CrawlerRawMinerFilesResponse {
  return { crawlerId: "", s3Paths: [] };
}

export const CrawlerRawMinerFilesResponse: MessageFns<CrawlerRawMinerFilesResponse> =
  {
    encode(
      message: CrawlerRawMinerFilesResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.crawlerId !== "") {
        writer.uint32(10).string(message.crawlerId);
      }
      for (const v of message.s3Paths) {
        writer.uint32(18).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): CrawlerRawMinerFilesResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseCrawlerRawMinerFilesResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.crawlerId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.s3Paths.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): CrawlerRawMinerFilesResponse {
      return {
        crawlerId: isSet(object.crawlerId)
          ? globalThis.String(object.crawlerId)
          : "",
        s3Paths: globalThis.Array.isArray(object?.s3Paths)
          ? object.s3Paths.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: CrawlerRawMinerFilesResponse): unknown {
      const obj: any = {};
      if (message.crawlerId !== "") {
        obj.crawlerId = message.crawlerId;
      }
      if (message.s3Paths?.length) {
        obj.s3Paths = message.s3Paths;
      }
      return obj;
    },

    create(
      base?: DeepPartial<CrawlerRawMinerFilesResponse>,
    ): CrawlerRawMinerFilesResponse {
      return CrawlerRawMinerFilesResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<CrawlerRawMinerFilesResponse>,
    ): CrawlerRawMinerFilesResponse {
      const message = createBaseCrawlerRawMinerFilesResponse();
      message.crawlerId = object.crawlerId ?? "";
      message.s3Paths = object.s3Paths?.map(e => e) || [];
      return message;
    },
  };

function createBaseDatasetFileWithId(): DatasetFileWithId {
  return {
    datasetId: "",
    fileName: "",
    fileSizeBytes: 0,
    lastModified: undefined,
    numRows: 0,
    s3Key: "",
    url: "",
    nebulaUrl: "",
  };
}

export const DatasetFileWithId: MessageFns<DatasetFileWithId> = {
  encode(
    message: DatasetFileWithId,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.datasetId !== "") {
      writer.uint32(10).string(message.datasetId);
    }
    if (message.fileName !== "") {
      writer.uint32(18).string(message.fileName);
    }
    if (message.fileSizeBytes !== 0) {
      writer.uint32(24).uint64(message.fileSizeBytes);
    }
    if (message.lastModified !== undefined) {
      Timestamp.encode(
        toTimestamp(message.lastModified),
        writer.uint32(34).fork(),
      ).join();
    }
    if (message.numRows !== 0) {
      writer.uint32(40).uint64(message.numRows);
    }
    if (message.s3Key !== "") {
      writer.uint32(50).string(message.s3Key);
    }
    if (message.url !== "") {
      writer.uint32(58).string(message.url);
    }
    if (message.nebulaUrl !== "") {
      writer.uint32(66).string(message.nebulaUrl);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatasetFileWithId {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasetFileWithId();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.datasetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.fileName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.fileSizeBytes = longToNumber(reader.uint64());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.lastModified = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.numRows = longToNumber(reader.uint64());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.s3Key = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.url = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.nebulaUrl = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatasetFileWithId {
    return {
      datasetId: isSet(object.datasetId)
        ? globalThis.String(object.datasetId)
        : "",
      fileName: isSet(object.fileName)
        ? globalThis.String(object.fileName)
        : "",
      fileSizeBytes: isSet(object.fileSizeBytes)
        ? globalThis.Number(object.fileSizeBytes)
        : 0,
      lastModified: isSet(object.lastModified)
        ? fromJsonTimestamp(object.lastModified)
        : undefined,
      numRows: isSet(object.numRows) ? globalThis.Number(object.numRows) : 0,
      s3Key: isSet(object.s3Key) ? globalThis.String(object.s3Key) : "",
      url: isSet(object.url) ? globalThis.String(object.url) : "",
      nebulaUrl: isSet(object.nebulaUrl)
        ? globalThis.String(object.nebulaUrl)
        : "",
    };
  },

  toJSON(message: DatasetFileWithId): unknown {
    const obj: any = {};
    if (message.datasetId !== "") {
      obj.datasetId = message.datasetId;
    }
    if (message.fileName !== "") {
      obj.fileName = message.fileName;
    }
    if (message.fileSizeBytes !== 0) {
      obj.fileSizeBytes = Math.round(message.fileSizeBytes);
    }
    if (message.lastModified !== undefined) {
      obj.lastModified = message.lastModified.toISOString();
    }
    if (message.numRows !== 0) {
      obj.numRows = Math.round(message.numRows);
    }
    if (message.s3Key !== "") {
      obj.s3Key = message.s3Key;
    }
    if (message.url !== "") {
      obj.url = message.url;
    }
    if (message.nebulaUrl !== "") {
      obj.nebulaUrl = message.nebulaUrl;
    }
    return obj;
  },

  create(base?: DeepPartial<DatasetFileWithId>): DatasetFileWithId {
    return DatasetFileWithId.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<DatasetFileWithId>): DatasetFileWithId {
    const message = createBaseDatasetFileWithId();
    message.datasetId = object.datasetId ?? "";
    message.fileName = object.fileName ?? "";
    message.fileSizeBytes = object.fileSizeBytes ?? 0;
    message.lastModified = object.lastModified ?? undefined;
    message.numRows = object.numRows ?? 0;
    message.s3Key = object.s3Key ?? "";
    message.url = object.url ?? "";
    message.nebulaUrl = object.nebulaUrl ?? "";
    return message;
  },
};

function createBaseGetGravityTaskDatasetFilesResponse(): GetGravityTaskDatasetFilesResponse {
  return { gravityTaskId: "", crawlerDatasetFiles: [] };
}

export const GetGravityTaskDatasetFilesResponse: MessageFns<GetGravityTaskDatasetFilesResponse> =
  {
    encode(
      message: GetGravityTaskDatasetFilesResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      for (const v of message.crawlerDatasetFiles) {
        CrawlerDatasetFiles.encode(v!, writer.uint32(18).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetGravityTaskDatasetFilesResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetGravityTaskDatasetFilesResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.crawlerDatasetFiles.push(
              CrawlerDatasetFiles.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetGravityTaskDatasetFilesResponse {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
        crawlerDatasetFiles: globalThis.Array.isArray(
          object?.crawlerDatasetFiles,
        )
          ? object.crawlerDatasetFiles.map((e: any) =>
              CrawlerDatasetFiles.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetGravityTaskDatasetFilesResponse): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      if (message.crawlerDatasetFiles?.length) {
        obj.crawlerDatasetFiles = message.crawlerDatasetFiles.map(e =>
          CrawlerDatasetFiles.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetGravityTaskDatasetFilesResponse>,
    ): GetGravityTaskDatasetFilesResponse {
      return GetGravityTaskDatasetFilesResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetGravityTaskDatasetFilesResponse>,
    ): GetGravityTaskDatasetFilesResponse {
      const message = createBaseGetGravityTaskDatasetFilesResponse();
      message.gravityTaskId = object.gravityTaskId ?? "";
      message.crawlerDatasetFiles =
        object.crawlerDatasetFiles?.map(e =>
          CrawlerDatasetFiles.fromPartial(e),
        ) || [];
      return message;
    },
  };

function createBaseGetCrawlerHistoryRequest(): GetCrawlerHistoryRequest {
  return { gravityTaskId: "" };
}

export const GetCrawlerHistoryRequest: MessageFns<GetCrawlerHistoryRequest> = {
  encode(
    message: GetCrawlerHistoryRequest,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.gravityTaskId !== "") {
      writer.uint32(10).string(message.gravityTaskId);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): GetCrawlerHistoryRequest {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGetCrawlerHistoryRequest();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gravityTaskId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GetCrawlerHistoryRequest {
    return {
      gravityTaskId: isSet(object.gravityTaskId)
        ? globalThis.String(object.gravityTaskId)
        : "",
    };
  },

  toJSON(message: GetCrawlerHistoryRequest): unknown {
    const obj: any = {};
    if (message.gravityTaskId !== "") {
      obj.gravityTaskId = message.gravityTaskId;
    }
    return obj;
  },

  create(
    base?: DeepPartial<GetCrawlerHistoryRequest>,
  ): GetCrawlerHistoryRequest {
    return GetCrawlerHistoryRequest.fromPartial(base ?? {});
  },
  fromPartial(
    object: DeepPartial<GetCrawlerHistoryRequest>,
  ): GetCrawlerHistoryRequest {
    const message = createBaseGetCrawlerHistoryRequest();
    message.gravityTaskId = object.gravityTaskId ?? "";
    return message;
  },
};

function createBaseCrawlerHistoryEntry(): CrawlerHistoryEntry {
  return { ingestDt: undefined, recordsCollected: 0, bytesCollected: 0 };
}

export const CrawlerHistoryEntry: MessageFns<CrawlerHistoryEntry> = {
  encode(
    message: CrawlerHistoryEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.ingestDt !== undefined) {
      Timestamp.encode(
        toTimestamp(message.ingestDt),
        writer.uint32(10).fork(),
      ).join();
    }
    if (message.recordsCollected !== 0) {
      writer.uint32(16).int64(message.recordsCollected);
    }
    if (message.bytesCollected !== 0) {
      writer.uint32(24).int64(message.bytesCollected);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): CrawlerHistoryEntry {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerHistoryEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.ingestDt = fromTimestamp(
            Timestamp.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.recordsCollected = longToNumber(reader.int64());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.bytesCollected = longToNumber(reader.int64());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerHistoryEntry {
    return {
      ingestDt: isSet(object.ingestDt)
        ? fromJsonTimestamp(object.ingestDt)
        : undefined,
      recordsCollected: isSet(object.recordsCollected)
        ? globalThis.Number(object.recordsCollected)
        : 0,
      bytesCollected: isSet(object.bytesCollected)
        ? globalThis.Number(object.bytesCollected)
        : 0,
    };
  },

  toJSON(message: CrawlerHistoryEntry): unknown {
    const obj: any = {};
    if (message.ingestDt !== undefined) {
      obj.ingestDt = message.ingestDt.toISOString();
    }
    if (message.recordsCollected !== 0) {
      obj.recordsCollected = Math.round(message.recordsCollected);
    }
    if (message.bytesCollected !== 0) {
      obj.bytesCollected = Math.round(message.bytesCollected);
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerHistoryEntry>): CrawlerHistoryEntry {
    return CrawlerHistoryEntry.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerHistoryEntry>): CrawlerHistoryEntry {
    const message = createBaseCrawlerHistoryEntry();
    message.ingestDt = object.ingestDt ?? undefined;
    message.recordsCollected = object.recordsCollected ?? 0;
    message.bytesCollected = object.bytesCollected ?? 0;
    return message;
  },
};

function createBaseCrawlerCriteriaAndHistory(): CrawlerCriteriaAndHistory {
  return {
    crawlerId: "",
    platform: "",
    topic: undefined,
    keyword: undefined,
    postStartDate: undefined,
    postEndDate: undefined,
    crawlerHistory: [],
  };
}

export const CrawlerCriteriaAndHistory: MessageFns<CrawlerCriteriaAndHistory> =
  {
    encode(
      message: CrawlerCriteriaAndHistory,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.crawlerId !== "") {
        writer.uint32(10).string(message.crawlerId);
      }
      if (message.platform !== "") {
        writer.uint32(18).string(message.platform);
      }
      if (message.topic !== undefined) {
        writer.uint32(26).string(message.topic);
      }
      if (message.keyword !== undefined) {
        writer.uint32(34).string(message.keyword);
      }
      if (message.postStartDate !== undefined) {
        Timestamp.encode(
          toTimestamp(message.postStartDate),
          writer.uint32(42).fork(),
        ).join();
      }
      if (message.postEndDate !== undefined) {
        Timestamp.encode(
          toTimestamp(message.postEndDate),
          writer.uint32(50).fork(),
        ).join();
      }
      for (const v of message.crawlerHistory) {
        CrawlerHistoryEntry.encode(v!, writer.uint32(58).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): CrawlerCriteriaAndHistory {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseCrawlerCriteriaAndHistory();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.crawlerId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.platform = reader.string();
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.topic = reader.string();
            continue;
          }
          case 4: {
            if (tag !== 34) {
              break;
            }

            message.keyword = reader.string();
            continue;
          }
          case 5: {
            if (tag !== 42) {
              break;
            }

            message.postStartDate = fromTimestamp(
              Timestamp.decode(reader, reader.uint32()),
            );
            continue;
          }
          case 6: {
            if (tag !== 50) {
              break;
            }

            message.postEndDate = fromTimestamp(
              Timestamp.decode(reader, reader.uint32()),
            );
            continue;
          }
          case 7: {
            if (tag !== 58) {
              break;
            }

            message.crawlerHistory.push(
              CrawlerHistoryEntry.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): CrawlerCriteriaAndHistory {
      return {
        crawlerId: isSet(object.crawlerId)
          ? globalThis.String(object.crawlerId)
          : "",
        platform: isSet(object.platform)
          ? globalThis.String(object.platform)
          : "",
        topic: isSet(object.topic)
          ? globalThis.String(object.topic)
          : undefined,
        keyword: isSet(object.keyword)
          ? globalThis.String(object.keyword)
          : undefined,
        postStartDate: isSet(object.postStartDate)
          ? fromJsonTimestamp(object.postStartDate)
          : undefined,
        postEndDate: isSet(object.postEndDate)
          ? fromJsonTimestamp(object.postEndDate)
          : undefined,
        crawlerHistory: globalThis.Array.isArray(object?.crawlerHistory)
          ? object.crawlerHistory.map((e: any) =>
              CrawlerHistoryEntry.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: CrawlerCriteriaAndHistory): unknown {
      const obj: any = {};
      if (message.crawlerId !== "") {
        obj.crawlerId = message.crawlerId;
      }
      if (message.platform !== "") {
        obj.platform = message.platform;
      }
      if (message.topic !== undefined) {
        obj.topic = message.topic;
      }
      if (message.keyword !== undefined) {
        obj.keyword = message.keyword;
      }
      if (message.postStartDate !== undefined) {
        obj.postStartDate = message.postStartDate.toISOString();
      }
      if (message.postEndDate !== undefined) {
        obj.postEndDate = message.postEndDate.toISOString();
      }
      if (message.crawlerHistory?.length) {
        obj.crawlerHistory = message.crawlerHistory.map(e =>
          CrawlerHistoryEntry.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<CrawlerCriteriaAndHistory>,
    ): CrawlerCriteriaAndHistory {
      return CrawlerCriteriaAndHistory.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<CrawlerCriteriaAndHistory>,
    ): CrawlerCriteriaAndHistory {
      const message = createBaseCrawlerCriteriaAndHistory();
      message.crawlerId = object.crawlerId ?? "";
      message.platform = object.platform ?? "";
      message.topic = object.topic ?? undefined;
      message.keyword = object.keyword ?? undefined;
      message.postStartDate = object.postStartDate ?? undefined;
      message.postEndDate = object.postEndDate ?? undefined;
      message.crawlerHistory =
        object.crawlerHistory?.map(e => CrawlerHistoryEntry.fromPartial(e)) ||
        [];
      return message;
    },
  };

function createBaseGetCrawlerHistoryResponse(): GetCrawlerHistoryResponse {
  return { gravityTaskId: "", crawlers: [] };
}

export const GetCrawlerHistoryResponse: MessageFns<GetCrawlerHistoryResponse> =
  {
    encode(
      message: GetCrawlerHistoryResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.gravityTaskId !== "") {
        writer.uint32(10).string(message.gravityTaskId);
      }
      for (const v of message.crawlers) {
        CrawlerCriteriaAndHistory.encode(v!, writer.uint32(18).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetCrawlerHistoryResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetCrawlerHistoryResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.gravityTaskId = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.crawlers.push(
              CrawlerCriteriaAndHistory.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetCrawlerHistoryResponse {
      return {
        gravityTaskId: isSet(object.gravityTaskId)
          ? globalThis.String(object.gravityTaskId)
          : "",
        crawlers: globalThis.Array.isArray(object?.crawlers)
          ? object.crawlers.map((e: any) =>
              CrawlerCriteriaAndHistory.fromJSON(e),
            )
          : [],
      };
    },

    toJSON(message: GetCrawlerHistoryResponse): unknown {
      const obj: any = {};
      if (message.gravityTaskId !== "") {
        obj.gravityTaskId = message.gravityTaskId;
      }
      if (message.crawlers?.length) {
        obj.crawlers = message.crawlers.map(e =>
          CrawlerCriteriaAndHistory.toJSON(e),
        );
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetCrawlerHistoryResponse>,
    ): GetCrawlerHistoryResponse {
      return GetCrawlerHistoryResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetCrawlerHistoryResponse>,
    ): GetCrawlerHistoryResponse {
      const message = createBaseGetCrawlerHistoryResponse();
      message.gravityTaskId = object.gravityTaskId ?? "";
      message.crawlers =
        object.crawlers?.map(e => CrawlerCriteriaAndHistory.fromPartial(e)) ||
        [];
      return message;
    },
  };

function createBaseGetCrawlerDataForDDSubmissionRequest(): GetCrawlerDataForDDSubmissionRequest {
  return { dsns: [] };
}

export const GetCrawlerDataForDDSubmissionRequest: MessageFns<GetCrawlerDataForDDSubmissionRequest> =
  {
    encode(
      message: GetCrawlerDataForDDSubmissionRequest,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.dsns) {
        writer.uint32(10).string(v!);
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetCrawlerDataForDDSubmissionRequest {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetCrawlerDataForDDSubmissionRequest();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.dsns.push(reader.string());
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetCrawlerDataForDDSubmissionRequest {
      return {
        dsns: globalThis.Array.isArray(object?.dsns)
          ? object.dsns.map((e: any) => globalThis.String(e))
          : [],
      };
    },

    toJSON(message: GetCrawlerDataForDDSubmissionRequest): unknown {
      const obj: any = {};
      if (message.dsns?.length) {
        obj.dsns = message.dsns;
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetCrawlerDataForDDSubmissionRequest>,
    ): GetCrawlerDataForDDSubmissionRequest {
      return GetCrawlerDataForDDSubmissionRequest.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetCrawlerDataForDDSubmissionRequest>,
    ): GetCrawlerDataForDDSubmissionRequest {
      const message = createBaseGetCrawlerDataForDDSubmissionRequest();
      message.dsns = object.dsns?.map(e => e) || [];
      return message;
    },
  };

function createBaseGetCrawlerDataForDDSubmissionResponse(): GetCrawlerDataForDDSubmissionResponse {
  return { crawlers: [] };
}

export const GetCrawlerDataForDDSubmissionResponse: MessageFns<GetCrawlerDataForDDSubmissionResponse> =
  {
    encode(
      message: GetCrawlerDataForDDSubmissionResponse,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      for (const v of message.crawlers) {
        CrawlerDataForDD.encode(v!, writer.uint32(10).fork()).join();
      }
      return writer;
    },

    decode(
      input: BinaryReader | Uint8Array,
      length?: number,
    ): GetCrawlerDataForDDSubmissionResponse {
      const reader =
        input instanceof BinaryReader ? input : new BinaryReader(input);
      let end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseGetCrawlerDataForDDSubmissionResponse();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.crawlers.push(
              CrawlerDataForDD.decode(reader, reader.uint32()),
            );
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): GetCrawlerDataForDDSubmissionResponse {
      return {
        crawlers: globalThis.Array.isArray(object?.crawlers)
          ? object.crawlers.map((e: any) => CrawlerDataForDD.fromJSON(e))
          : [],
      };
    },

    toJSON(message: GetCrawlerDataForDDSubmissionResponse): unknown {
      const obj: any = {};
      if (message.crawlers?.length) {
        obj.crawlers = message.crawlers.map(e => CrawlerDataForDD.toJSON(e));
      }
      return obj;
    },

    create(
      base?: DeepPartial<GetCrawlerDataForDDSubmissionResponse>,
    ): GetCrawlerDataForDDSubmissionResponse {
      return GetCrawlerDataForDDSubmissionResponse.fromPartial(base ?? {});
    },
    fromPartial(
      object: DeepPartial<GetCrawlerDataForDDSubmissionResponse>,
    ): GetCrawlerDataForDDSubmissionResponse {
      const message = createBaseGetCrawlerDataForDDSubmissionResponse();
      message.crawlers =
        object.crawlers?.map(e => CrawlerDataForDD.fromPartial(e)) || [];
      return message;
    },
  };

function createBaseCrawlerDataForDD(): CrawlerDataForDD {
  return {
    crawlerId: "",
    platform: "",
    topic: undefined,
    keyword: undefined,
    postStartDatetime: undefined,
    postEndDatetime: undefined,
  };
}

export const CrawlerDataForDD: MessageFns<CrawlerDataForDD> = {
  encode(
    message: CrawlerDataForDD,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.crawlerId !== "") {
      writer.uint32(10).string(message.crawlerId);
    }
    if (message.platform !== "") {
      writer.uint32(18).string(message.platform);
    }
    if (message.topic !== undefined) {
      writer.uint32(26).string(message.topic);
    }
    if (message.keyword !== undefined) {
      writer.uint32(34).string(message.keyword);
    }
    if (message.postStartDatetime !== undefined) {
      writer.uint32(42).string(message.postStartDatetime);
    }
    if (message.postEndDatetime !== undefined) {
      writer.uint32(50).string(message.postEndDatetime);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CrawlerDataForDD {
    const reader =
      input instanceof BinaryReader ? input : new BinaryReader(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCrawlerDataForDD();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.crawlerId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.platform = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.topic = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.keyword = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.postStartDatetime = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.postEndDatetime = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CrawlerDataForDD {
    return {
      crawlerId: isSet(object.crawlerId)
        ? globalThis.String(object.crawlerId)
        : "",
      platform: isSet(object.platform)
        ? globalThis.String(object.platform)
        : "",
      topic: isSet(object.topic) ? globalThis.String(object.topic) : undefined,
      keyword: isSet(object.keyword)
        ? globalThis.String(object.keyword)
        : undefined,
      postStartDatetime: isSet(object.postStartDatetime)
        ? globalThis.String(object.postStartDatetime)
        : undefined,
      postEndDatetime: isSet(object.postEndDatetime)
        ? globalThis.String(object.postEndDatetime)
        : undefined,
    };
  },

  toJSON(message: CrawlerDataForDD): unknown {
    const obj: any = {};
    if (message.crawlerId !== "") {
      obj.crawlerId = message.crawlerId;
    }
    if (message.platform !== "") {
      obj.platform = message.platform;
    }
    if (message.topic !== undefined) {
      obj.topic = message.topic;
    }
    if (message.keyword !== undefined) {
      obj.keyword = message.keyword;
    }
    if (message.postStartDatetime !== undefined) {
      obj.postStartDatetime = message.postStartDatetime;
    }
    if (message.postEndDatetime !== undefined) {
      obj.postEndDatetime = message.postEndDatetime;
    }
    return obj;
  },

  create(base?: DeepPartial<CrawlerDataForDD>): CrawlerDataForDD {
    return CrawlerDataForDD.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<CrawlerDataForDD>): CrawlerDataForDD {
    const message = createBaseCrawlerDataForDD();
    message.crawlerId = object.crawlerId ?? "";
    message.platform = object.platform ?? "";
    message.topic = object.topic ?? undefined;
    message.keyword = object.keyword ?? undefined;
    message.postStartDatetime = object.postStartDatetime ?? undefined;
    message.postEndDatetime = object.postEndDatetime ?? undefined;
    return message;
  },
};

export type GravityServiceService = typeof GravityServiceService;
export const GravityServiceService = {
  /** Lists all data collection tasks for a user */
  getPopularTags: {
    path: "/gravity.v1.GravityService/GetPopularTags",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetPopularTagsResponse) =>
      Buffer.from(GetPopularTagsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetPopularTagsResponse.decode(value),
  },
  /** Lists all data collection tasks for a user */
  getGravityTasks: {
    path: "/gravity.v1.GravityService/GetGravityTasks",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetGravityTasksRequest) =>
      Buffer.from(GetGravityTasksRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetGravityTasksRequest.decode(value),
    responseSerialize: (value: GetGravityTasksResponse) =>
      Buffer.from(GetGravityTasksResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetGravityTasksResponse.decode(value),
  },
  /** Get all marketplace crawlers */
  getMarketplaceCrawlers: {
    path: "/gravity.v1.GravityService/GetMarketplaceCrawlers",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetMarketplaceCrawlersResponse) =>
      Buffer.from(GetMarketplaceCrawlersResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetMarketplaceCrawlersResponse.decode(value),
  },
  /** Gets raw miner files for a specific crawler */
  getCrawlerRawMinerFiles: {
    path: "/gravity.v1.GravityService/GetCrawlerRawMinerFiles",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetCrawlerRequest) =>
      Buffer.from(GetCrawlerRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetCrawlerRequest.decode(value),
    responseSerialize: (value: CrawlerRawMinerFilesResponse) =>
      Buffer.from(CrawlerRawMinerFilesResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      CrawlerRawMinerFilesResponse.decode(value),
  },
  /** Get the parent workflow id (the id of the ui workflow) for this crawler */
  getCrawlerParentTaskId: {
    path: "/gravity.v1.GravityService/GetCrawlerParentTaskId",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetCrawlerRequest) =>
      Buffer.from(GetCrawlerRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetCrawlerRequest.decode(value),
    responseSerialize: (value: CreateGravityTaskResponse) =>
      Buffer.from(CreateGravityTaskResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      CreateGravityTaskResponse.decode(value),
  },
  /** Add a persistent gravity task to the Gravity state DB */
  addPersistentGravityTask: {
    path: "/gravity.v1.GravityService/AddPersistentGravityTask",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AddPersistentGravityTaskRequest) =>
      Buffer.from(AddPersistentGravityTaskRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      AddPersistentGravityTaskRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Add a persistent dataset workflow to the Gravity state DB */
  addPersistentDatasetWorkflows: {
    path: "/gravity.v1.GravityService/AddPersistentDatasetWorkflows",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: AddPersistentDatasetWorkflowsRequest) =>
      Buffer.from(AddPersistentDatasetWorkflowsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      AddPersistentDatasetWorkflowsRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Retrieve recent persistent dataset workflows (last 7 days, non-Completed) */
  getPersistentDatasetWorkflows: {
    path: "/gravity.v1.GravityService/GetPersistentDatasetWorkflows",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetPersistentDatasetWorkflowsResponse) =>
      Buffer.from(GetPersistentDatasetWorkflowsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetPersistentDatasetWorkflowsResponse.decode(value),
  },
  /** Retrieve all persistent gravity tasks from the Gravity state DB */
  getPersistentGravityTasks: {
    path: "/gravity.v1.GravityService/GetPersistentGravityTasks",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetPersistentGravityTasksResponse) =>
      Buffer.from(GetPersistentGravityTasksResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetPersistentGravityTasksResponse.decode(value),
  },
  /** Get a single crawler by its ID */
  getCrawler: {
    path: "/gravity.v1.GravityService/GetCrawler",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetCrawlerRequest) =>
      Buffer.from(GetCrawlerRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetCrawlerRequest.decode(value),
    responseSerialize: (value: GetCrawlerResponse) =>
      Buffer.from(GetCrawlerResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetCrawlerResponse.decode(value),
  },
  /** Upsert marketplace task metadata */
  upsertMarketplaceTaskMetadata: {
    path: "/gravity.v1.GravityService/UpsertMarketplaceTaskMetadata",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertMarketplaceTaskMetadataRequest) =>
      Buffer.from(UpsertMarketplaceTaskMetadataRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      UpsertMarketplaceTaskMetadataRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upsert marketplace task suggestions */
  upsertMarketplaceTaskSuggestions: {
    path: "/gravity.v1.GravityService/UpsertMarketplaceTaskSuggestions",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertMarketplaceTaskSuggestionsRequest) =>
      Buffer.from(
        UpsertMarketplaceTaskSuggestionsRequest.encode(value).finish(),
      ),
    requestDeserialize: (value: Buffer) =>
      UpsertMarketplaceTaskSuggestionsRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Get marketplace task suggestions */
  getMarketplaceTaskSuggestions: {
    path: "/gravity.v1.GravityService/GetMarketplaceTaskSuggestions",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetMarketplaceTaskSuggestionsRequest) =>
      Buffer.from(GetMarketplaceTaskSuggestionsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetMarketplaceTaskSuggestionsRequest.decode(value),
    responseSerialize: (value: GetMarketplaceDatasetsResponse) =>
      Buffer.from(GetMarketplaceDatasetsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetMarketplaceDatasetsResponse.decode(value),
  },
  /** Create a new gravity task */
  createGravityTask: {
    path: "/gravity.v1.GravityService/CreateGravityTask",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CreateGravityTaskRequest) =>
      Buffer.from(CreateGravityTaskRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      CreateGravityTaskRequest.decode(value),
    responseSerialize: (value: CreateGravityTaskResponse) =>
      Buffer.from(CreateGravityTaskResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      CreateGravityTaskResponse.decode(value),
  },
  /** Build a dataset for a single crawler */
  buildDataset: {
    path: "/gravity.v1.GravityService/BuildDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: BuildDatasetRequest) =>
      Buffer.from(BuildDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => BuildDatasetRequest.decode(value),
    responseSerialize: (value: BuildDatasetResponse) =>
      Buffer.from(BuildDatasetResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => BuildDatasetResponse.decode(value),
  },
  /** Get the dataset build status and results */
  getDataset: {
    path: "/gravity.v1.GravityService/GetDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetDatasetRequest) =>
      Buffer.from(GetDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => GetDatasetRequest.decode(value),
    responseSerialize: (value: GetDatasetResponse) =>
      Buffer.from(GetDatasetResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetDatasetResponse.decode(value),
  },
  /** Add a persistent topic to the Gravity state DB */
  addPersistentTopic: {
    path: "/gravity.v1.GravityService/AddPersistentTopic",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: PersistentTopic) =>
      Buffer.from(PersistentTopic.encode(value).finish()),
    requestDeserialize: (value: Buffer) => PersistentTopic.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Cancel a gravity task and any crawlers associated with it */
  cancelGravityTask: {
    path: "/gravity.v1.GravityService/CancelGravityTask",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CancelGravityTaskRequest) =>
      Buffer.from(CancelGravityTaskRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      CancelGravityTaskRequest.decode(value),
    responseSerialize: (value: CancelGravityTaskResponse) =>
      Buffer.from(CancelGravityTaskResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      CancelGravityTaskResponse.decode(value),
  },
  /** Cancel dataset build if it is in progress and purges the dataset */
  cancelDataset: {
    path: "/gravity.v1.GravityService/CancelDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CancelDatasetRequest) =>
      Buffer.from(CancelDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CancelDatasetRequest.decode(value),
    responseSerialize: (value: CancelDatasetResponse) =>
      Buffer.from(CancelDatasetResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => CancelDatasetResponse.decode(value),
  },
  /** Refund user if fewer rows are returned */
  datasetBillingCorrection: {
    path: "/gravity.v1.GravityService/DatasetBillingCorrection",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: DatasetBillingCorrectionRequest) =>
      Buffer.from(DatasetBillingCorrectionRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      DatasetBillingCorrectionRequest.decode(value),
    responseSerialize: (value: DatasetBillingCorrectionResponse) =>
      Buffer.from(DatasetBillingCorrectionResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      DatasetBillingCorrectionResponse.decode(value),
  },
  /** Gets the available datsets for use in Dataset Marketplace */
  getMarketplaceDatasets: {
    path: "/gravity.v1.GravityService/GetMarketplaceDatasets",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetMarketplaceDatasetsRequest) =>
      Buffer.from(GetMarketplaceDatasetsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetMarketplaceDatasetsRequest.decode(value),
    responseSerialize: (value: GetMarketplaceDatasetsResponse) =>
      Buffer.from(GetMarketplaceDatasetsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetMarketplaceDatasetsResponse.decode(value),
  },
  /** Gets all dataset files for a given gravity task */
  getGravityTaskDatasetFiles: {
    path: "/gravity.v1.GravityService/GetGravityTaskDatasetFiles",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetGravityTaskDatasetFilesRequest) =>
      Buffer.from(GetGravityTaskDatasetFilesRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetGravityTaskDatasetFilesRequest.decode(value),
    responseSerialize: (value: GetGravityTaskDatasetFilesResponse) =>
      Buffer.from(GetGravityTaskDatasetFilesResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetGravityTaskDatasetFilesResponse.decode(value),
  },
  /** Gets all dataset files for a given persistent gravity task (no user_id check, validates against persistent tasks table) */
  getGravityMarketplaceTaskDatasetFiles: {
    path: "/gravity.v1.GravityService/GetGravityMarketplaceTaskDatasetFiles",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetGravityTaskDatasetFilesRequest) =>
      Buffer.from(GetGravityTaskDatasetFilesRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetGravityTaskDatasetFilesRequest.decode(value),
    responseSerialize: (value: GetGravityTaskDatasetFilesResponse) =>
      Buffer.from(GetGravityTaskDatasetFilesResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetGravityTaskDatasetFilesResponse.decode(value),
  },
  /** Publishes a dataset into the Marketplace */
  publishDataset: {
    path: "/gravity.v1.GravityService/PublishDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: PublishDatasetRequest) =>
      Buffer.from(PublishDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => PublishDatasetRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Get crawler data for DD submission */
  getCrawlerDataForDdSubmission: {
    path: "/gravity.v1.GravityService/GetCrawlerDataForDDSubmission",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetCrawlerDataForDDSubmissionRequest) =>
      Buffer.from(GetCrawlerDataForDDSubmissionRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetCrawlerDataForDDSubmissionRequest.decode(value),
    responseSerialize: (value: GetCrawlerDataForDDSubmissionResponse) =>
      Buffer.from(GetCrawlerDataForDDSubmissionResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetCrawlerDataForDDSubmissionResponse.decode(value),
  },
  /** Upserts a crawler into the Gravity state DB */
  upsertCrawler: {
    path: "/gravity.v1.GravityService/UpsertCrawler",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertCrawlerRequest) =>
      Buffer.from(UpsertCrawlerRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpsertCrawlerRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upserts a crawler criteria into the Gravity state DB */
  insertCrawlerCriteria: {
    path: "/gravity.v1.GravityService/InsertCrawlerCriteria",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: InsertCrawlerCriteriaRequest) =>
      Buffer.from(InsertCrawlerCriteriaRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      InsertCrawlerCriteriaRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upserts a gravity task into the Gravity state DB */
  upsertGravityTask: {
    path: "/gravity.v1.GravityService/UpsertGravityTask",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertGravityTaskRequest) =>
      Buffer.from(UpsertGravityTaskRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      UpsertGravityTaskRequest.decode(value),
    responseSerialize: (value: UpsertGravityTaskResponse) =>
      Buffer.from(UpsertGravityTaskResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      UpsertGravityTaskResponse.decode(value),
  },
  /** Upserts a dataset into to the Gravity state DB */
  upsertDataset: {
    path: "/gravity.v1.GravityService/UpsertDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertDatasetRequest) =>
      Buffer.from(UpsertDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpsertDatasetRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Inserts a dataset file row into the Gravity state DB */
  insertDatasetFile: {
    path: "/gravity.v1.GravityService/InsertDatasetFile",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: InsertDatasetFileRequest) =>
      Buffer.from(InsertDatasetFileRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      InsertDatasetFileRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upserts a nebula into the Gravity nebula DB */
  upsertNebula: {
    path: "/gravity.v1.GravityService/UpsertNebula",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertNebulaRequest) =>
      Buffer.from(UpsertNebulaRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpsertNebulaRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Builds all datasets for a task (additionally cancels crawlers with no data) */
  buildAllDatasets: {
    path: "/gravity.v1.GravityService/BuildAllDatasets",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: BuildAllDatasetsRequest) =>
      Buffer.from(BuildAllDatasetsRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      BuildAllDatasetsRequest.decode(value),
    responseSerialize: (value: BuildAllDatasetsResponse) =>
      Buffer.from(BuildAllDatasetsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      BuildAllDatasetsResponse.decode(value),
  },
  /** Gets all persistent topics from the Gravity state DB */
  getPersistentTopics: {
    path: "/gravity.v1.GravityService/GetPersistentTopics",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: PersistentTopicResponse) =>
      Buffer.from(PersistentTopicResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      PersistentTopicResponse.decode(value),
  },
  /** Gets crawler history for a gravity task */
  getCrawlerHistory: {
    path: "/gravity.v1.GravityService/GetCrawlerHistory",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: GetCrawlerHistoryRequest) =>
      Buffer.from(GetCrawlerHistoryRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      GetCrawlerHistoryRequest.decode(value),
    responseSerialize: (value: GetCrawlerHistoryResponse) =>
      Buffer.from(GetCrawlerHistoryResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetCrawlerHistoryResponse.decode(value),
  },
  /** Completes a crawler */
  completeCrawler: {
    path: "/gravity.v1.GravityService/CompleteCrawler",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: CompleteCrawlerRequest) =>
      Buffer.from(CompleteCrawlerRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => CompleteCrawlerRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertRawMinerFiles: {
    path: "/gravity.v1.GravityService/UpsertRawMinerFiles",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Crawler) =>
      Buffer.from(Crawler.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Crawler.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertHotkeys: {
    path: "/gravity.v1.GravityService/UpsertHotkeys",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: UpsertHotkeysRequest) =>
      Buffer.from(UpsertHotkeysRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) => UpsertHotkeysRequest.decode(value),
    responseSerialize: (value: UpsertResponse) =>
      Buffer.from(UpsertResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => UpsertResponse.decode(value),
  },
  /** Gets all hotkeys from the Gravity state DB */
  getHotkeys: {
    path: "/gravity.v1.GravityService/GetHotkeys",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetHotkeysResponse) =>
      Buffer.from(GetHotkeysResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) => GetHotkeysResponse.decode(value),
  },
  /** Purchase a marketplace dataset */
  buyMarketplaceDataset: {
    path: "/gravity.v1.GravityService/BuyMarketplaceDataset",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: BuyMarketplaceDatasetRequest) =>
      Buffer.from(BuyMarketplaceDatasetRequest.encode(value).finish()),
    requestDeserialize: (value: Buffer) =>
      BuyMarketplaceDatasetRequest.decode(value),
    responseSerialize: (value: BuyMarketplaceDatasetResponse) =>
      Buffer.from(BuyMarketplaceDatasetResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      BuyMarketplaceDatasetResponse.decode(value),
  },
  /** Get all marketplace datasets owned by the authenticated user */
  getUserMarketplaceDatasets: {
    path: "/gravity.v1.GravityService/GetUserMarketplaceDatasets",
    requestStream: false,
    responseStream: false,
    requestSerialize: (value: Empty) =>
      Buffer.from(Empty.encode(value).finish()),
    requestDeserialize: (value: Buffer) => Empty.decode(value),
    responseSerialize: (value: GetUserMarketplaceDatasetsResponse) =>
      Buffer.from(GetUserMarketplaceDatasetsResponse.encode(value).finish()),
    responseDeserialize: (value: Buffer) =>
      GetUserMarketplaceDatasetsResponse.decode(value),
  },
} as const;

export interface GravityServiceServer extends UntypedServiceImplementation {
  /** Lists all data collection tasks for a user */
  getPopularTags: handleUnaryCall<Empty, GetPopularTagsResponse>;
  /** Lists all data collection tasks for a user */
  getGravityTasks: handleUnaryCall<
    GetGravityTasksRequest,
    GetGravityTasksResponse
  >;
  /** Get all marketplace crawlers */
  getMarketplaceCrawlers: handleUnaryCall<
    Empty,
    GetMarketplaceCrawlersResponse
  >;
  /** Gets raw miner files for a specific crawler */
  getCrawlerRawMinerFiles: handleUnaryCall<
    GetCrawlerRequest,
    CrawlerRawMinerFilesResponse
  >;
  /** Get the parent workflow id (the id of the ui workflow) for this crawler */
  getCrawlerParentTaskId: handleUnaryCall<
    GetCrawlerRequest,
    CreateGravityTaskResponse
  >;
  /** Add a persistent gravity task to the Gravity state DB */
  addPersistentGravityTask: handleUnaryCall<
    AddPersistentGravityTaskRequest,
    UpsertResponse
  >;
  /** Add a persistent dataset workflow to the Gravity state DB */
  addPersistentDatasetWorkflows: handleUnaryCall<
    AddPersistentDatasetWorkflowsRequest,
    UpsertResponse
  >;
  /** Retrieve recent persistent dataset workflows (last 7 days, non-Completed) */
  getPersistentDatasetWorkflows: handleUnaryCall<
    Empty,
    GetPersistentDatasetWorkflowsResponse
  >;
  /** Retrieve all persistent gravity tasks from the Gravity state DB */
  getPersistentGravityTasks: handleUnaryCall<
    Empty,
    GetPersistentGravityTasksResponse
  >;
  /** Get a single crawler by its ID */
  getCrawler: handleUnaryCall<GetCrawlerRequest, GetCrawlerResponse>;
  /** Upsert marketplace task metadata */
  upsertMarketplaceTaskMetadata: handleUnaryCall<
    UpsertMarketplaceTaskMetadataRequest,
    UpsertResponse
  >;
  /** Upsert marketplace task suggestions */
  upsertMarketplaceTaskSuggestions: handleUnaryCall<
    UpsertMarketplaceTaskSuggestionsRequest,
    UpsertResponse
  >;
  /** Get marketplace task suggestions */
  getMarketplaceTaskSuggestions: handleUnaryCall<
    GetMarketplaceTaskSuggestionsRequest,
    GetMarketplaceDatasetsResponse
  >;
  /** Create a new gravity task */
  createGravityTask: handleUnaryCall<
    CreateGravityTaskRequest,
    CreateGravityTaskResponse
  >;
  /** Build a dataset for a single crawler */
  buildDataset: handleUnaryCall<BuildDatasetRequest, BuildDatasetResponse>;
  /** Get the dataset build status and results */
  getDataset: handleUnaryCall<GetDatasetRequest, GetDatasetResponse>;
  /** Add a persistent topic to the Gravity state DB */
  addPersistentTopic: handleUnaryCall<PersistentTopic, UpsertResponse>;
  /** Cancel a gravity task and any crawlers associated with it */
  cancelGravityTask: handleUnaryCall<
    CancelGravityTaskRequest,
    CancelGravityTaskResponse
  >;
  /** Cancel dataset build if it is in progress and purges the dataset */
  cancelDataset: handleUnaryCall<CancelDatasetRequest, CancelDatasetResponse>;
  /** Refund user if fewer rows are returned */
  datasetBillingCorrection: handleUnaryCall<
    DatasetBillingCorrectionRequest,
    DatasetBillingCorrectionResponse
  >;
  /** Gets the available datsets for use in Dataset Marketplace */
  getMarketplaceDatasets: handleUnaryCall<
    GetMarketplaceDatasetsRequest,
    GetMarketplaceDatasetsResponse
  >;
  /** Gets all dataset files for a given gravity task */
  getGravityTaskDatasetFiles: handleUnaryCall<
    GetGravityTaskDatasetFilesRequest,
    GetGravityTaskDatasetFilesResponse
  >;
  /** Gets all dataset files for a given persistent gravity task (no user_id check, validates against persistent tasks table) */
  getGravityMarketplaceTaskDatasetFiles: handleUnaryCall<
    GetGravityTaskDatasetFilesRequest,
    GetGravityTaskDatasetFilesResponse
  >;
  /** Publishes a dataset into the Marketplace */
  publishDataset: handleUnaryCall<PublishDatasetRequest, UpsertResponse>;
  /** Get crawler data for DD submission */
  getCrawlerDataForDdSubmission: handleUnaryCall<
    GetCrawlerDataForDDSubmissionRequest,
    GetCrawlerDataForDDSubmissionResponse
  >;
  /** Upserts a crawler into the Gravity state DB */
  upsertCrawler: handleUnaryCall<UpsertCrawlerRequest, UpsertResponse>;
  /** Upserts a crawler criteria into the Gravity state DB */
  insertCrawlerCriteria: handleUnaryCall<
    InsertCrawlerCriteriaRequest,
    UpsertResponse
  >;
  /** Upserts a gravity task into the Gravity state DB */
  upsertGravityTask: handleUnaryCall<
    UpsertGravityTaskRequest,
    UpsertGravityTaskResponse
  >;
  /** Upserts a dataset into to the Gravity state DB */
  upsertDataset: handleUnaryCall<UpsertDatasetRequest, UpsertResponse>;
  /** Inserts a dataset file row into the Gravity state DB */
  insertDatasetFile: handleUnaryCall<InsertDatasetFileRequest, UpsertResponse>;
  /** Upserts a nebula into the Gravity nebula DB */
  upsertNebula: handleUnaryCall<UpsertNebulaRequest, UpsertResponse>;
  /** Builds all datasets for a task (additionally cancels crawlers with no data) */
  buildAllDatasets: handleUnaryCall<
    BuildAllDatasetsRequest,
    BuildAllDatasetsResponse
  >;
  /** Gets all persistent topics from the Gravity state DB */
  getPersistentTopics: handleUnaryCall<Empty, PersistentTopicResponse>;
  /** Gets crawler history for a gravity task */
  getCrawlerHistory: handleUnaryCall<
    GetCrawlerHistoryRequest,
    GetCrawlerHistoryResponse
  >;
  /** Completes a crawler */
  completeCrawler: handleUnaryCall<CompleteCrawlerRequest, UpsertResponse>;
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertRawMinerFiles: handleUnaryCall<Crawler, UpsertResponse>;
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertHotkeys: handleUnaryCall<UpsertHotkeysRequest, UpsertResponse>;
  /** Gets all hotkeys from the Gravity state DB */
  getHotkeys: handleUnaryCall<Empty, GetHotkeysResponse>;
  /** Purchase a marketplace dataset */
  buyMarketplaceDataset: handleUnaryCall<
    BuyMarketplaceDatasetRequest,
    BuyMarketplaceDatasetResponse
  >;
  /** Get all marketplace datasets owned by the authenticated user */
  getUserMarketplaceDatasets: handleUnaryCall<
    Empty,
    GetUserMarketplaceDatasetsResponse
  >;
}

export interface GravityServiceClient extends Client {
  /** Lists all data collection tasks for a user */
  getPopularTags(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetPopularTagsResponse,
    ) => void,
  ): ClientUnaryCall;
  getPopularTags(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetPopularTagsResponse,
    ) => void,
  ): ClientUnaryCall;
  getPopularTags(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetPopularTagsResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Lists all data collection tasks for a user */
  getGravityTasks(
    request: GetGravityTasksRequest,
    callback: (
      error: ServiceError | null,
      response: GetGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityTasks(
    request: GetGravityTasksRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityTasks(
    request: GetGravityTasksRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Get all marketplace crawlers */
  getMarketplaceCrawlers(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceCrawlersResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceCrawlers(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceCrawlersResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceCrawlers(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceCrawlersResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets raw miner files for a specific crawler */
  getCrawlerRawMinerFiles(
    request: GetCrawlerRequest,
    callback: (
      error: ServiceError | null,
      response: CrawlerRawMinerFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerRawMinerFiles(
    request: GetCrawlerRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: CrawlerRawMinerFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerRawMinerFiles(
    request: GetCrawlerRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: CrawlerRawMinerFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Get the parent workflow id (the id of the ui workflow) for this crawler */
  getCrawlerParentTaskId(
    request: GetCrawlerRequest,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerParentTaskId(
    request: GetCrawlerRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerParentTaskId(
    request: GetCrawlerRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Add a persistent gravity task to the Gravity state DB */
  addPersistentGravityTask(
    request: AddPersistentGravityTaskRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentGravityTask(
    request: AddPersistentGravityTaskRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentGravityTask(
    request: AddPersistentGravityTaskRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Add a persistent dataset workflow to the Gravity state DB */
  addPersistentDatasetWorkflows(
    request: AddPersistentDatasetWorkflowsRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentDatasetWorkflows(
    request: AddPersistentDatasetWorkflowsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentDatasetWorkflows(
    request: AddPersistentDatasetWorkflowsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Retrieve recent persistent dataset workflows (last 7 days, non-Completed) */
  getPersistentDatasetWorkflows(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetPersistentDatasetWorkflowsResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentDatasetWorkflows(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetPersistentDatasetWorkflowsResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentDatasetWorkflows(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetPersistentDatasetWorkflowsResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Retrieve all persistent gravity tasks from the Gravity state DB */
  getPersistentGravityTasks(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetPersistentGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentGravityTasks(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetPersistentGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentGravityTasks(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetPersistentGravityTasksResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Get a single crawler by its ID */
  getCrawler(
    request: GetCrawlerRequest,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawler(
    request: GetCrawlerRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawler(
    request: GetCrawlerRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Upsert marketplace task metadata */
  upsertMarketplaceTaskMetadata(
    request: UpsertMarketplaceTaskMetadataRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertMarketplaceTaskMetadata(
    request: UpsertMarketplaceTaskMetadataRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertMarketplaceTaskMetadata(
    request: UpsertMarketplaceTaskMetadataRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upsert marketplace task suggestions */
  upsertMarketplaceTaskSuggestions(
    request: UpsertMarketplaceTaskSuggestionsRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertMarketplaceTaskSuggestions(
    request: UpsertMarketplaceTaskSuggestionsRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertMarketplaceTaskSuggestions(
    request: UpsertMarketplaceTaskSuggestionsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Get marketplace task suggestions */
  getMarketplaceTaskSuggestions(
    request: GetMarketplaceTaskSuggestionsRequest,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceTaskSuggestions(
    request: GetMarketplaceTaskSuggestionsRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceTaskSuggestions(
    request: GetMarketplaceTaskSuggestionsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Create a new gravity task */
  createGravityTask(
    request: CreateGravityTaskRequest,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  createGravityTask(
    request: CreateGravityTaskRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  createGravityTask(
    request: CreateGravityTaskRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: CreateGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Build a dataset for a single crawler */
  buildDataset(
    request: BuildDatasetRequest,
    callback: (
      error: ServiceError | null,
      response: BuildDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  buildDataset(
    request: BuildDatasetRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: BuildDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  buildDataset(
    request: BuildDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: BuildDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Get the dataset build status and results */
  getDataset(
    request: GetDatasetRequest,
    callback: (
      error: ServiceError | null,
      response: GetDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  getDataset(
    request: GetDatasetRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  getDataset(
    request: GetDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Add a persistent topic to the Gravity state DB */
  addPersistentTopic(
    request: PersistentTopic,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentTopic(
    request: PersistentTopic,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  addPersistentTopic(
    request: PersistentTopic,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Cancel a gravity task and any crawlers associated with it */
  cancelGravityTask(
    request: CancelGravityTaskRequest,
    callback: (
      error: ServiceError | null,
      response: CancelGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  cancelGravityTask(
    request: CancelGravityTaskRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: CancelGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  cancelGravityTask(
    request: CancelGravityTaskRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: CancelGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Cancel dataset build if it is in progress and purges the dataset */
  cancelDataset(
    request: CancelDatasetRequest,
    callback: (
      error: ServiceError | null,
      response: CancelDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  cancelDataset(
    request: CancelDatasetRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: CancelDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  cancelDataset(
    request: CancelDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: CancelDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Refund user if fewer rows are returned */
  datasetBillingCorrection(
    request: DatasetBillingCorrectionRequest,
    callback: (
      error: ServiceError | null,
      response: DatasetBillingCorrectionResponse,
    ) => void,
  ): ClientUnaryCall;
  datasetBillingCorrection(
    request: DatasetBillingCorrectionRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: DatasetBillingCorrectionResponse,
    ) => void,
  ): ClientUnaryCall;
  datasetBillingCorrection(
    request: DatasetBillingCorrectionRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: DatasetBillingCorrectionResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets the available datsets for use in Dataset Marketplace */
  getMarketplaceDatasets(
    request: GetMarketplaceDatasetsRequest,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceDatasets(
    request: GetMarketplaceDatasetsRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getMarketplaceDatasets(
    request: GetMarketplaceDatasetsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets all dataset files for a given gravity task */
  getGravityTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets all dataset files for a given persistent gravity task (no user_id check, validates against persistent tasks table) */
  getGravityMarketplaceTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityMarketplaceTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  getGravityMarketplaceTaskDatasetFiles(
    request: GetGravityTaskDatasetFilesRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetGravityTaskDatasetFilesResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Publishes a dataset into the Marketplace */
  publishDataset(
    request: PublishDatasetRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  publishDataset(
    request: PublishDatasetRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  publishDataset(
    request: PublishDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Get crawler data for DD submission */
  getCrawlerDataForDdSubmission(
    request: GetCrawlerDataForDDSubmissionRequest,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerDataForDDSubmissionResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerDataForDdSubmission(
    request: GetCrawlerDataForDDSubmissionRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerDataForDDSubmissionResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerDataForDdSubmission(
    request: GetCrawlerDataForDDSubmissionRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerDataForDDSubmissionResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Upserts a crawler into the Gravity state DB */
  upsertCrawler(
    request: UpsertCrawlerRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertCrawler(
    request: UpsertCrawlerRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertCrawler(
    request: UpsertCrawlerRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upserts a crawler criteria into the Gravity state DB */
  insertCrawlerCriteria(
    request: InsertCrawlerCriteriaRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  insertCrawlerCriteria(
    request: InsertCrawlerCriteriaRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  insertCrawlerCriteria(
    request: InsertCrawlerCriteriaRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upserts a gravity task into the Gravity state DB */
  upsertGravityTask(
    request: UpsertGravityTaskRequest,
    callback: (
      error: ServiceError | null,
      response: UpsertGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  upsertGravityTask(
    request: UpsertGravityTaskRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: UpsertGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  upsertGravityTask(
    request: UpsertGravityTaskRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: UpsertGravityTaskResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Upserts a dataset into to the Gravity state DB */
  upsertDataset(
    request: UpsertDatasetRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertDataset(
    request: UpsertDatasetRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertDataset(
    request: UpsertDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Inserts a dataset file row into the Gravity state DB */
  insertDatasetFile(
    request: InsertDatasetFileRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  insertDatasetFile(
    request: InsertDatasetFileRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  insertDatasetFile(
    request: InsertDatasetFileRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upserts a nebula into the Gravity nebula DB */
  upsertNebula(
    request: UpsertNebulaRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertNebula(
    request: UpsertNebulaRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertNebula(
    request: UpsertNebulaRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Builds all datasets for a task (additionally cancels crawlers with no data) */
  buildAllDatasets(
    request: BuildAllDatasetsRequest,
    callback: (
      error: ServiceError | null,
      response: BuildAllDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  buildAllDatasets(
    request: BuildAllDatasetsRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: BuildAllDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  buildAllDatasets(
    request: BuildAllDatasetsRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: BuildAllDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets all persistent topics from the Gravity state DB */
  getPersistentTopics(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: PersistentTopicResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentTopics(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: PersistentTopicResponse,
    ) => void,
  ): ClientUnaryCall;
  getPersistentTopics(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: PersistentTopicResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Gets crawler history for a gravity task */
  getCrawlerHistory(
    request: GetCrawlerHistoryRequest,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerHistoryResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerHistory(
    request: GetCrawlerHistoryRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerHistoryResponse,
    ) => void,
  ): ClientUnaryCall;
  getCrawlerHistory(
    request: GetCrawlerHistoryRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetCrawlerHistoryResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Completes a crawler */
  completeCrawler(
    request: CompleteCrawlerRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  completeCrawler(
    request: CompleteCrawlerRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  completeCrawler(
    request: CompleteCrawlerRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertRawMinerFiles(
    request: Crawler,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertRawMinerFiles(
    request: Crawler,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertRawMinerFiles(
    request: Crawler,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Upserts raw miner files (parquet paths) for a crawler */
  upsertHotkeys(
    request: UpsertHotkeysRequest,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertHotkeys(
    request: UpsertHotkeysRequest,
    metadata: Metadata,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  upsertHotkeys(
    request: UpsertHotkeysRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (error: ServiceError | null, response: UpsertResponse) => void,
  ): ClientUnaryCall;
  /** Gets all hotkeys from the Gravity state DB */
  getHotkeys(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetHotkeysResponse,
    ) => void,
  ): ClientUnaryCall;
  getHotkeys(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetHotkeysResponse,
    ) => void,
  ): ClientUnaryCall;
  getHotkeys(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetHotkeysResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Purchase a marketplace dataset */
  buyMarketplaceDataset(
    request: BuyMarketplaceDatasetRequest,
    callback: (
      error: ServiceError | null,
      response: BuyMarketplaceDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  buyMarketplaceDataset(
    request: BuyMarketplaceDatasetRequest,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: BuyMarketplaceDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  buyMarketplaceDataset(
    request: BuyMarketplaceDatasetRequest,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: BuyMarketplaceDatasetResponse,
    ) => void,
  ): ClientUnaryCall;
  /** Get all marketplace datasets owned by the authenticated user */
  getUserMarketplaceDatasets(
    request: Empty,
    callback: (
      error: ServiceError | null,
      response: GetUserMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getUserMarketplaceDatasets(
    request: Empty,
    metadata: Metadata,
    callback: (
      error: ServiceError | null,
      response: GetUserMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
  getUserMarketplaceDatasets(
    request: Empty,
    metadata: Metadata,
    options: Partial<CallOptions>,
    callback: (
      error: ServiceError | null,
      response: GetUserMarketplaceDatasetsResponse,
    ) => void,
  ): ClientUnaryCall;
}

export const GravityServiceClient = makeGenericClientConstructor(
  GravityServiceService,
  "gravity.v1.GravityService",
) as unknown as {
  new (
    address: string,
    credentials: ChannelCredentials,
    options?: Partial<ClientOptions>,
  ): GravityServiceClient;
  service: typeof GravityServiceService;
  serviceName: string;
};

type Builtin =
  | Date
  | Function
  | Uint8Array
  | string
  | number
  | boolean
  | undefined;

export type DeepPartial<T> = T extends Builtin
  ? T
  : T extends globalThis.Array<infer U>
    ? globalThis.Array<DeepPartial<U>>
    : T extends ReadonlyArray<infer U>
      ? ReadonlyArray<DeepPartial<U>>
      : T extends {}
        ? { [K in keyof T]?: DeepPartial<T[K]> }
        : Partial<T>;

function toTimestamp(date: Date): Timestamp {
  const seconds = Math.trunc(date.getTime() / 1_000);
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function longToNumber(int64: { toString(): string }): number {
  const num = globalThis.Number(int64.toString());
  if (num > globalThis.Number.MAX_SAFE_INTEGER) {
    throw new globalThis.Error("Value is larger than Number.MAX_SAFE_INTEGER");
  }
  if (num < globalThis.Number.MIN_SAFE_INTEGER) {
    throw new globalThis.Error("Value is smaller than Number.MIN_SAFE_INTEGER");
  }
  return num;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create(base?: DeepPartial<T>): T;
  fromPartial(object: DeepPartial<T>): T;
}
